{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncapacitated Facility Location Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Personal modules\n",
    "\n",
    "# Plotting modules\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Linear programming modules\n",
    "import pulp\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# == Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# == Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# == Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "# == Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# == Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      "    food_per_person_per_day: 0.00087617 \n",
      "    transport_cost_per_ton_per_km: 3364.0\n",
      "\n",
      "data information: \n",
      "    population: (558, 71) \n",
      "    distance: (558, 558) \n",
      "    warehouses: \n",
      "    Type  capacity_ton        cost\n",
      "0     1          1074  3111202.75\n",
      "1     2          2418  4804980.75 \n",
      "\n",
      "population memory usage: 0.31 MB\n",
      "distance memory usage: 2.38 MB\n",
      "warehouses memory usage: 0.00 MB\n",
      "Elapsed time: 0.23 s\n"
     ]
    }
   ],
   "source": [
    "# import the data and parameters and check the data\n",
    "\n",
    "data_path = \"data/\"\n",
    "start_time = time.time()\n",
    "# ====Parameters==== #\n",
    "parameters = pd.read_csv(os.path.join(data_path, \"parametros.csv\"))\n",
    "# 1. food_per_person_per_day in tons per day\n",
    "food_per_person_per_day = float(\n",
    "    parameters.loc[parameters[\"parametro\"] == \"comida_por_persona_en_toneladas\"].values[\n",
    "        0\n",
    "    ][1]\n",
    ")\n",
    "# 2. transport_cost_per_ton_per_km in COP per ton per km\n",
    "transport_cost_per_ton_per_km = float(\n",
    "    parameters.loc[\n",
    "        parameters[\"parametro\"] == \"costo_de_transporte_por_tonelada_por_kilomentro\"\n",
    "    ].values[0][1]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"parameters: \\n    food_per_person_per_day: {food_per_person_per_day} \\n    transport_cost_per_ton_per_km: {transport_cost_per_ton_per_km}\\n\"\n",
    ")\n",
    "# ====Parameters==== #\n",
    "\n",
    "# ====importData==== #\n",
    "# 1. population, from data/municipios_procesado.csv\n",
    "population = pd.read_csv(\n",
    "    os.path.join(data_path, \"municipios_procesado.csv\"), index_col=3\n",
    ")\n",
    "# 2. distance, from data/distance_matrix_final.csv\n",
    "distance = pd.read_csv(\n",
    "    os.path.join(data_path, \"distance_matrix_final.csv\"), index_col=0\n",
    ")\n",
    "# 3. warehouses, from data/almacenes.csv\n",
    "warehouses = pd.read_csv(os.path.join(data_path, \"almacenes.csv\"))\n",
    "# ====importData==== #\n",
    "\n",
    "# ====DataProcessing===== #\n",
    "# fill the nan values in population with the minimum '2024' from the departamento of Chocó for the columns 22:\n",
    "population.loc[population.isna().any(axis=1), population.columns[18:]] = (\n",
    "    population[\n",
    "        population[\"2024\"]\n",
    "        == population.loc[population[\"departamento\"] == \"Chocó\"][\"2024\"].min()\n",
    "    ]\n",
    "    .iloc[0, 18:]\n",
    "    .values\n",
    ")\n",
    "# drop the municipalities with nan values in the first column of the distance matrix\n",
    "distance = distance.dropna(subset=[distance.columns[0]], axis=0)\n",
    "distance = distance.dropna(subset=[distance.index[0]], axis=1)\n",
    "# turn the columns of distance into integers\n",
    "distance.columns = distance.columns.astype(int)\n",
    "\n",
    "distance = distance.sample(frac=0.5)\n",
    "distance = distance.loc[:, distance.index]\n",
    "\n",
    "# turn distance to km\n",
    "distance = distance / 1000\n",
    "# select only the rows in population dpmp that the index is in distance\n",
    "population = population.loc[distance.index]\n",
    "\n",
    "print(\n",
    "    f\"data information: \\n    population: {population.shape} \\n    distance: {distance.shape} \\n    warehouses: \\n {warehouses} \\n\"\n",
    ")\n",
    "# ====DataProcessing===== #\n",
    "\n",
    "# ====DataInformation==== #\n",
    "# Memory usage of the data\n",
    "print(f\"population memory usage: {population.memory_usage().sum()/1024**2:.2f} MB\")\n",
    "print(f\"distance memory usage: {distance.memory_usage().sum()/1024**2:.2f} MB\")\n",
    "print(f\"warehouses memory usage: {warehouses.memory_usage().sum()/1024**2:.2f} MB\")\n",
    "# ====DataInformation==== #\n",
    "\n",
    "# ====DataChecking==== #\n",
    "# Test to the data if needed\n",
    "# ====DataChecking==== #\n",
    "print(f\"Elapsed time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Demand Forecast\n",
    "\n",
    "we are using the data from the population dataset that has the colombian census information since 1985 to 2035, the current year is 2024 and the last census was performed in 2018, the data was taken on december 2023 from the DANE web page.\n",
    "\n",
    "First we need to check the current forecast, then use 4 ML algorithms and Deep Learning to create a new model. The Machine Learning algorithms are:\n",
    "- Multiple Linear Regression.\n",
    "- Regression Tree.\n",
    "- Support Vector Machine.\n",
    "- Random Forest Regression.\n",
    "\n",
    "Then, we need the Mean Absolute Error (MAE) to compare the models. The best model will be used to forecast the demand for the next 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression: 1.11 s\n",
      "    Mean Absolute Error: 0.43198437016072605\n",
      "    Mean Squared Error: 0.36721421672902976\n",
      "    R2 Score: 0.5765013921849211\n",
      "Regression Tree: 1.06 s\n",
      "    Mean Absolute Error: 0.09003335589892468\n",
      "    Mean Squared Error: 0.028677896418070038\n",
      "    R2 Score: 0.9695151061613836\n",
      "Support Vector Machine: 0.94 s\n",
      "    Mean Absolute Error: 0.10994280721415771\n",
      "    Mean Squared Error: 0.05892026856577378\n",
      "    R2 Score: 0.9417720815878418\n",
      "Random Forest Regression 10, 5: 5.91 s\n",
      "    Mean Absolute Error: 0.07303505078192633\n",
      "    Mean Squared Error: 0.024373078011182117\n",
      "    R2 Score: 0.9757296524373542\n",
      "Random Forest Regression 100, 10: 48.15 s\n",
      "    Mean Absolute Error: 0.05852193133709307\n",
      "    Mean Squared Error: 0.019474472525733477\n",
      "    R2 Score: 0.9800057551445567\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Demand Forecast\n",
    "\n",
    "# 1. Demand Forecast\n",
    "data = population.copy().iloc[:, 20:]\n",
    "data = data.transpose()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Multiple Linear Regression\": LinearRegression(),\n",
    "    \"Regression Tree\": DecisionTreeRegressor(\n",
    "        max_depth=100, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "    \"Support Vector Machine\": SVR(C=1.0, kernel=\"rbf\", gamma=\"scale\"),\n",
    "    \"Random Forest Regression 10, 5\": RandomForestRegressor(\n",
    "        n_estimators=10, max_depth=5, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "    \"Random Forest Regression 100, 10\": RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float(\"-inf\")\n",
    "results = {}\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    mean_absolute_errors = []\n",
    "    mean_squared_errors = []\n",
    "    r2_scores = []\n",
    "\n",
    "    # For each column in the data\n",
    "    for column in data.columns:\n",
    "        model.fit(train.index.values.reshape(-1, 1), train[column])\n",
    "        predictions = model.predict(test.index.values.reshape(-1, 1))\n",
    "        mean_absolute_errors.append(mean_absolute_error(test[column], predictions))\n",
    "        mean_squared_errors.append(mean_squared_error(test[column], predictions))\n",
    "        r2_scores.append(r2_score(test[column], predictions))\n",
    "\n",
    "    avg_r2_score = np.mean(r2_scores)\n",
    "    results[model_name] = {\n",
    "        \"time\": time.time() - start_time,\n",
    "        \"mean_absolute_error\": np.mean(mean_absolute_errors),\n",
    "        \"mean_squared_error\": np.mean(mean_squared_errors),\n",
    "        \"r2_score\": avg_r2_score,\n",
    "    }\n",
    "\n",
    "    if avg_r2_score > best_score:\n",
    "        best_score = avg_r2_score\n",
    "        best_model = model\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: {metrics['time']:.2f} s\")\n",
    "    print(f\"    Mean Absolute Error: {metrics['mean_absolute_error']}\")\n",
    "    print(f\"    Mean Squared Error: {metrics['mean_squared_error']}\")\n",
    "    print(f\"    R2 Score: {metrics['r2_score']}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "\n",
    "# Create the forecast per municipality since 1985 to 2024+30 years\n",
    "# Create a list to store all columns\n",
    "columns = []\n",
    "forecast = pd.DataFrame(index=np.arange(1985, 2024 + 30))\n",
    "# Iterate over each column in data\n",
    "for column in data.columns:\n",
    "    best_model.fit(data.index.values.reshape(-1, 1), data[column])\n",
    "    column_data = pd.DataFrame(\n",
    "        best_model.predict(np.arange(1985, 2024 + 30).reshape(-1, 1)), columns=[column]\n",
    "    )\n",
    "    columns.append(column_data)\n",
    "\n",
    "# Concatenate all columns at once\n",
    "forecast = pd.concat(columns, axis=1)\n",
    "\n",
    "\n",
    "# Inverse the standardization\n",
    "data = pd.DataFrame(\n",
    "    scaler.inverse_transform(data), index=data.index, columns=data.columns\n",
    ")\n",
    "forecast = pd.DataFrame(\n",
    "    scaler.inverse_transform(forecast), index=forecast.index, columns=forecast.columns\n",
    ")\n",
    "forecast.index = pd.RangeIndex(start=1985, stop=2024 + 30, step=1)\n",
    "\n",
    "# Plot the forecast\n",
    "fig = go.Figure()\n",
    "for column in forecast.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast.index,\n",
    "            y=forecast[column],\n",
    "            mode=\"lines+markers\",\n",
    "            name=column,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Population Forecast\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Population\",\n",
    "    legend_title=\"Municipality\",\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(\"html/forecast.html\")\n",
    "\n",
    "# Select the year 2024+30 and add the population to the population dataframe\n",
    "population[\"forecast\"] = forecast.loc[2024 + 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set facility types\n",
    "\n",
    "We have 3 types of facilities:\n",
    "- Type 1: Small facility.\n",
    "- Type 2: Medium facility.\n",
    "- Type 3: Large facility.\n",
    "\n",
    "for each facility type we have the following information:\n",
    "- Fixed cost.\n",
    "- Variable cost.\n",
    "\n",
    "The proposal is to use a mathematical model to determine the number of facilities of each type to minimize the total cost, in order to satisfy the demand. and be able to train a classifier to predict the type of facility that will be needed for the hole country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Objective function: 1952515963.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([(1.0, 0.0), (0.0, 1.0), (0.0, 6.0), (0.0, 4.0), (0.0, 2.0),\n",
       "       (3.0, 0.0), (0.0, 3.0), (0.0, 5.0), (0.0, 11.0)], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facility 0</th>\n",
       "      <th>Facility 1</th>\n",
       "      <th>demand</th>\n",
       "      <th>satisfied</th>\n",
       "      <th>cost</th>\n",
       "      <th>comb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpmp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.814682</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.327302</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15131</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.969087</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76275</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.804461</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.786874</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85279</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.573620</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>844.442132</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>4804980.75</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25843</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>407.268349</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68051</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.824295</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19821</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.430414</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>3111202.75</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Facility 0  Facility 1      demand  satisfied        cost        comb\n",
       "dpmp                                                                        \n",
       "52411         1.0         0.0   67.814682     1074.0  3111202.75  (1.0, 0.0)\n",
       "5585          1.0         0.0   98.327302     1074.0  3111202.75  (1.0, 0.0)\n",
       "15131         1.0         0.0   21.969087     1074.0  3111202.75  (1.0, 0.0)\n",
       "76275         1.0         0.0  356.804461     1074.0  3111202.75  (1.0, 0.0)\n",
       "5347          1.0         0.0   36.786874     1074.0  3111202.75  (1.0, 0.0)\n",
       "...           ...         ...         ...        ...         ...         ...\n",
       "85279         1.0         0.0   10.573620     1074.0  3111202.75  (1.0, 0.0)\n",
       "54498         0.0         1.0  844.442132     2418.0  4804980.75  (0.0, 1.0)\n",
       "25843         1.0         0.0  407.268349     1074.0  3111202.75  (1.0, 0.0)\n",
       "68051         1.0         0.0   55.824295     1074.0  3111202.75  (1.0, 0.0)\n",
       "19821         1.0         0.0  250.430414     1074.0  3111202.75  (1.0, 0.0)\n",
       "\n",
       "[558 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization of the model\n",
    "p = population.copy()[\"forecast\"]\n",
    "\n",
    "# ====Parameters==== #\n",
    "c_j = warehouses[\"capacity_ton\"].values.astype(float)\n",
    "f_j = warehouses[\"cost\"].values.astype(float)\n",
    "\n",
    "\n",
    "p_i = p.values.astype(int)\n",
    "n = food_per_person_per_day * 7\n",
    "d_i = p_i * n\n",
    "# Lambda = 2 for the top 32 municipalities, 1 for the rest\n",
    "lambda_i = np.ones(len(p_i)) * 1.1\n",
    "lambda_i[np.argsort(p_i)[-32:]] = 1.5\n",
    "# ====Parameters==== #\n",
    "\n",
    "\n",
    "# Decision variables: $x_{ij}$\n",
    "I = range(len(p_i))\n",
    "J = range(len(c_j))\n",
    "model = pulp.LpProblem(\"UFLP\", pulp.LpMinimize)\n",
    "x = pulp.LpVariable.dicts(\n",
    "    \"x\", ((i, j) for i in I for j in J), lowBound=0, cat=\"Integer\"\n",
    ")\n",
    "y = pulp.LpVariable.dicts(\"y\", ((i, j) for i in I for j in J), cat=\"Binary\")\n",
    "# Objective function\n",
    "model += (\n",
    "    pulp.lpSum(f_j[j] * x[(i, j)] for i in I for j in J),\n",
    "    \"Total cost of the facilities\",\n",
    ")\n",
    "# Constraints\n",
    "for i in I:\n",
    "    model += (\n",
    "        pulp.lpSum(c_j[j] * x[(i, j)] for j in J) >= d_i[i] * lambda_i[i],\n",
    "        f\"Population demand {i}\",\n",
    "    )\n",
    "    model += (\n",
    "        pulp.lpSum(x[(i, j)] for j in J) >= 1,\n",
    "        f\"Facility assignment {i}\",\n",
    "    )\n",
    "    model += (\n",
    "        pulp.lpSum(y[(i, j)] for j in J) == 1,\n",
    "        f\"Faacility assignment __ {i}\",\n",
    "    )\n",
    "    for j in J:\n",
    "        model += (\n",
    "            x[(i, j)] <= 100 * y[(i, j)],\n",
    "            f\"Fsacility assignment _ {i} _ {j}\",\n",
    "        )\n",
    "\n",
    "model += pulp.lpSum(x[(i, j)] * c_j[j] for i in I for j in J) >= pulp.lpSum(\n",
    "    d_i[i] * lambda_i[i] for i in I\n",
    ")\n",
    "\n",
    "\n",
    "# Solve the model\n",
    "model.solve(\n",
    "    solver=pulp.PULP_CBC_CMD(\n",
    "        logPath=\"logs/2 lp - solution.log\",\n",
    "        msg=False,\n",
    "        timeLimit=5 * 60,\n",
    "        threads=os.cpu_count(),\n",
    "    )\n",
    ")\n",
    "# Results\n",
    "print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
    "print(f\"Objective function: {pulp.value(model.objective)}\")\n",
    "df = pd.DataFrame(\n",
    "    [[pulp.value(x[(i, j)]) for j in J] for i in I],\n",
    "    columns=[f\"Facility {j}\" for j in J],\n",
    "    index=p.index,\n",
    ")\n",
    "df[\"demand\"] = d_i\n",
    "df[\"satisfied\"] = sum(df[f\"Facility {j}\"] * c_j[j] for j in J)\n",
    "df[\"cost\"] = sum(df[f\"Facility {j}\"] * f_j[j] for j in J)\n",
    "df[\"comb\"] = df.apply(lambda x: tuple(x[: len(J)]), axis=1)\n",
    "\n",
    "display(df.comb.unique().size, df.comb.unique())\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set facility capacity\n",
    "\n",
    "We have m types of facilities with different capacities, the proposal is to use the data generated in the previous step to determine the capacity of each facility type in order to satisfy the demand.\n",
    "Machine Learning algorithms will be used to Classify the type of facility that will be needed for each municipality.\n",
    "- Decision Tree.\n",
    "- Linear Discriminant Analysis.\n",
    "- Logistic Regression.\n",
    "- Support Vector Machine.\n",
    "\n",
    "and deep learning to create a new model. The best model will be used to determine the capacity of each facility type.\n",
    "\n",
    "The objective is to predict 'satisfied' with the demand of each municipality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31901/3768460403.py:10: DeprecationWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand</th>\n",
       "      <th>satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312.768157</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208.798320</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724.151876</td>\n",
       "      <td>2418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1445.684881</td>\n",
       "      <td>2418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928.035742</td>\n",
       "      <td>3222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2096.029949</td>\n",
       "      <td>3222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2553.314462</td>\n",
       "      <td>4836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2944.832779</td>\n",
       "      <td>4836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3835.175705</td>\n",
       "      <td>7254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3421.142448</td>\n",
       "      <td>7254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6192.436615</td>\n",
       "      <td>9672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5052.718184</td>\n",
       "      <td>9672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6729.495531</td>\n",
       "      <td>12090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8454.835476</td>\n",
       "      <td>14508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16855.999407</td>\n",
       "      <td>26598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          demand  satisfied\n",
       "0     312.768157     1074.0\n",
       "1     208.798320     1074.0\n",
       "2     724.151876     2418.0\n",
       "3    1445.684881     2418.0\n",
       "4    1928.035742     3222.0\n",
       "5    2096.029949     3222.0\n",
       "6    2553.314462     4836.0\n",
       "7    2944.832779     4836.0\n",
       "8    3835.175705     7254.0\n",
       "9    3421.142448     7254.0\n",
       "10   6192.436615     9672.0\n",
       "11   5052.718184     9672.0\n",
       "12   6729.495531    12090.0\n",
       "13   8454.835476    14508.0\n",
       "14  16855.999407    26598.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.01 s\n",
      "    Accuracy: 1.0\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Linear Discriminant Analysis: 0.01 s\n",
      "    Accuracy: 1.0\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Logistic Regression: 0.01 s\n",
      "    Accuracy: 0.26666666666666666\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      1.00      0.33         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.40      1.00      0.57         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.07      0.22      0.10        15\n",
      "weighted avg       0.08      0.27      0.12        15\n",
      "\n",
      "Support Vector Machine: 0.01 s\n",
      "    Accuracy: 0.7333333333333333\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       0.50      1.00      0.67         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.54      0.67      0.59        15\n",
      "weighted avg       0.58      0.73      0.64        15\n",
      "\n",
      "Deep Neural Network: 0.37 s\n",
      "    Accuracy: 1.0\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Best model: DecisionTreeClassifier(max_depth=100)\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(df.copy(), population.copy(), left_index=True, right_index=True)\n",
    "population[\"demand\"] = d_i\n",
    "population[\"_satisfied\"] = df[\"satisfied\"]\n",
    "population[\"_cost\"] = df[\"cost\"]\n",
    "\n",
    "\n",
    "data = data[[\"demand\", \"lat\", \"lon\", \"satisfied\", \"cost\"]]\n",
    "\n",
    "# Create table with the unique cases of satisfied and cost values, with a random sample of n of the demand, lat and lon\n",
    "unique_cases = data.groupby([\"satisfied\", \"cost\"]).apply(\n",
    "    lambda x: x.sample(n=2, random_state=0) if len(x) > 2 else x\n",
    ")\n",
    "data = unique_cases.reset_index(drop=True)[[\"demand\", \"satisfied\"]]\n",
    "display(data)\n",
    "le = LabelEncoder()\n",
    "data[\"satisfied\"] = le.fit_transform(data[\"satisfied\"])\n",
    "scaler = MinMaxScaler()\n",
    "data[[\"demand\"]] = scaler.fit_transform(data[[\"demand\"]])\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data.drop(columns=[\"satisfied\"]), data[\"satisfied\"], test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "train_x, test_x = data.drop(columns=[\"satisfied\"]), data.drop(columns=[\"satisfied\"])\n",
    "train_y, test_y = data[\"satisfied\"], data[\"satisfied\"]\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        max_depth=100, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine\": SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\"),\n",
    "    \"Deep Neural Network\": MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100, 100),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=1000,\n",
    "        random_state=0,\n",
    "    ),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float(\"-inf\")\n",
    "results = {}\n",
    "metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"confusion_matrix\": [],\n",
    "    \"classification_report\": [],\n",
    "    \"time\": [],\n",
    "}\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    confusion = confusion_matrix(test_y, predictions)\n",
    "    classification = classification_report(test_y, predictions, zero_division=0)\n",
    "    results[model_name] = {\n",
    "        \"time\": time.time() - start_time,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": confusion,\n",
    "        \"classification_report\": classification,\n",
    "    }\n",
    "\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_model = model\n",
    "\n",
    "    metrics[\"accuracy\"].append(accuracy)\n",
    "    metrics[\"confusion_matrix\"].append(confusion)\n",
    "    metrics[\"classification_report\"].append(classification)\n",
    "    metrics[\"time\"].append(time.time() - start_time)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: {metrics['time']:.2f} s\")\n",
    "    print(f\"    Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"    Confusion Matrix: {metrics['confusion_matrix']}\")\n",
    "    print(f\"    Classification Report: {metrics['classification_report']}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "\n",
    "# Classify the data for the population data for every model\n",
    "for model_name, model in models.items():\n",
    "    population[f\"_satisfied {model_name}\"] = model.predict(population[[\"demand\"]])\n",
    "    population[f\"_satisfied {model_name}\"] = le.inverse_transform(\n",
    "        population[f\"_satisfied {model_name}\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Propose a k parameter for clustering using Linear Programming\n",
    "\n",
    "The proposal is to use the data generated in the previous step to determine the number of clusters that will be needed to satisfy the demand. The objective is to minimize the total cost of the facilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data (replace with your actual data)\n",
    "data = population.copy()\n",
    "data = data.loc[:, [\"lat\", \"lon\"]]\n",
    "data = StandardScaler().fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=[\"lat\", \"lon\"], index=population.copy().index)\n",
    "# Initialize dictionaries to store metrics\n",
    "metrics = {\"inertia\": [], \"silhouette\": [], \"davies_bouldin\": []}\n",
    "\n",
    "# Range for the number of clusters\n",
    "cluster_range = range(2, 20)\n",
    "\n",
    "# Calculate metrics for each number of clusters\n",
    "for i in cluster_range:\n",
    "    model = KMeans(n_clusters=i, random_state=0)\n",
    "    model.fit(data[[\"lat\", \"lon\"]])\n",
    "    metrics[\"inertia\"].append(model.inertia_)\n",
    "    metrics[\"silhouette\"].append(silhouette_score(data[[\"lat\", \"lon\"]], model.labels_))\n",
    "    metrics[\"davies_bouldin\"].append(\n",
    "        davies_bouldin_score(data[[\"lat\", \"lon\"]], model.labels_)\n",
    "    )\n",
    "\n",
    "# Create interactive plots using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Inertia Plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(cluster_range),\n",
    "        y=metrics[\"inertia\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Inertia\",\n",
    "        yaxis=\"y\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Silhouette Plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(cluster_range),\n",
    "        y=metrics[\"silhouette\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Silhouette Score\",\n",
    "        yaxis=\"y2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Davies-Bouldin Plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(cluster_range),\n",
    "        y=metrics[\"davies_bouldin\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Davies-Bouldin Score\",\n",
    "        yaxis=\"y2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Clustering Metrics\",\n",
    "    xaxis_title=\"Number of Clusters\",\n",
    "    yaxis_title=\"Inertia\",\n",
    "    legend_title=\"Metric\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis=dict(side=\"left\", showgrid=False, zeroline=False, title=\"Normalized Inertia\"),\n",
    "    yaxis2=dict(\n",
    "        side=\"right\",\n",
    "        overlaying=\"y\",\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        title=\"Normalized Score (0-1)\",\n",
    "        title_standoff=10,  # Adjust the distance between the axis title and axis tick labels\n",
    "    ),\n",
    "    margin=dict(r=100, t=100),  # Adjust the right and top margins\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "# fig.show()\n",
    "fig.write_html(\"html/clustering_metrics.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.23 s\n",
      "Status: Optimal\n",
      "Objective function: 7.299507717210783\n",
      "Number of facilities: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([45, 17])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = population.copy()\n",
    "dist = distance.copy()\n",
    "muestra = 0.1\n",
    "randomSeed = np.random.randint(0, 1000)\n",
    "dist = dist.sample(frac=muestra, random_state=0, axis=0).sample(\n",
    "    frac=muestra, random_state=0, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Select the same rows than the distance matrix\n",
    "data = data.loc[dist.copy().index]\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "dist = MinMaxScaler().fit_transform(dist)\n",
    "fixed_cost = max(dist.flatten()) * (1 + muestra)\n",
    "\n",
    "\n",
    "model = pulp.LpProblem(\"UFLP\", pulp.LpMinimize)\n",
    "\n",
    "\n",
    "# Decision variables\n",
    "I = range(len(data))\n",
    "J = range(len(data))\n",
    "\n",
    "\n",
    "x = pulp.LpVariable.dicts(\"x\", ((i, j) for i in I for j in J), cat=\"Binary\")\n",
    "y = pulp.LpVariable.dicts(\"y\", J, cat=\"Binary\")\n",
    "\n",
    "\n",
    "# Objective function\n",
    "model += (\n",
    "    pulp.lpSum(dist[i][j] * x[(i, j)] for i in I for j in J)\n",
    "    + fixed_cost * pulp.lpSum(y[j] for j in J),\n",
    "    \"Total cost\",\n",
    ")\n",
    "\n",
    "\n",
    "# Constraints\n",
    "for i in I:\n",
    "    model += pulp.lpSum(x[(i, j)] for j in J) == 1, f\"Population demand {i}\"\n",
    "\n",
    "\n",
    "for j in J:\n",
    "    for i in I:\n",
    "        model += x[(i, j)] <= y[j], f\"Facility assignment {i} {j}\"\n",
    "\n",
    "\n",
    "# Solve the model\n",
    "start_time = time.time()\n",
    "model.solve(\n",
    "    solver=pulp.PULP_CBC_CMD(\n",
    "        logPath=\"logs/4 - lp solution.log\",\n",
    "        msg=False,\n",
    "        timeLimit=60 * 60,\n",
    "        threads=os.cpu_count(),\n",
    "    )\n",
    ")\n",
    "print(f\"Elapsed time: {time.time() - start_time:.2f} s\")\n",
    "# Results\n",
    "print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
    "print(f\"Objective function: {pulp.value(model.objective)}\")\n",
    "print(f\"Number of facilities: {pulp.value(pulp.lpSum(y[j] for j in J))}\")\n",
    "proposed_k = pulp.value(pulp.lpSum(y[j] for j in J))\n",
    "\n",
    "\n",
    "df = pd.DataFrame([[pulp.value(x[(i, j)]) for j in J] for i in I], columns=J, index=I)\n",
    "\n",
    "\n",
    "# Turn the results into labels for the clusters\n",
    "df[\"cluster\"] = df.idxmax(axis=1)\n",
    "display(df[\"cluster\"].unique().size / muestra, df[\"cluster\"].unique())\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=data[\"lat\"],\n",
    "        lon=data[\"lon\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=df[\"cluster\"],\n",
    "            colorscale=\"Viridis\",\n",
    "            cmin=0,\n",
    "            cmax=df[\"cluster\"].max(),\n",
    "            colorbar=dict(title=\"Cluster\"),\n",
    "        ),\n",
    "        text=data.index,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Clusters\",\n",
    "    mapbox=dict(\n",
    "        style=\"open-street-map\",\n",
    "        center=dict(lat=4.5, lon=-74),\n",
    "        zoom=3,\n",
    "    ),\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(\"html/clusters.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solve the CFLP inside every cluster\n",
    "\n",
    "Here, we will use the clusters to find the local optimum to the cflp inside the clusters generated with the following clustering algorithms:\n",
    "\n",
    "- KMeans\n",
    "- SOM\n",
    "- AgglomerativeClustering\n",
    "- DBSCAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['SOM', 'KMeans', 'Agglomerative', 'DBSCAN'],\n",
       " 'silhouette': [0.5879340004476247],\n",
       " 'davies_bouldin': [0.6990381689706499],\n",
       " 'n_clusters': [6, 6, 6, 13],\n",
       " 'time': [0.12101101875305176,\n",
       "  0.04090070724487305,\n",
       "  0.011110544204711914,\n",
       "  0.0057909488677978516]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = population.copy()\n",
    "data = data.loc[:, [\"lat\", \"lon\"]]\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=[\"lat\", \"lon\"], index=population.copy().index)\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "metrics = {\n",
    "    \"model\": [],\n",
    "    \"silhouette\": [],\n",
    "    \"davies_bouldin\": [],\n",
    "    \"n_clusters\": [],\n",
    "    \"time\": [],\n",
    "}\n",
    "\n",
    "# Range for the number of clusters\n",
    "n_clusters = 6\n",
    "# models to evaluate\n",
    "models = {\n",
    "    \"SOM\": SOM(dim=2, random_state=0, m=3, n=2),\n",
    "    \"KMeans\": KMeans(n_clusters=n_clusters, random_state=0),\n",
    "    \"Agglomerative\": AgglomerativeClustering(n_clusters=n_clusters),\n",
    "    \"DBSCAN\": DBSCAN(eps=0.15, min_samples=6),\n",
    "}\n",
    "\n",
    "# Calculate metrics for each number of clusters and save the best model\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    if model_name == \"SOM\":\n",
    "        model.fit(data[[\"lat\", \"lon\"]].to_numpy())\n",
    "        data[f\"{model_name}_cluster\"] = model.predict(data[[\"lat\", \"lon\"]].to_numpy())\n",
    "        metrics[\"silhouette\"].append(\n",
    "            silhouette_score(data, model.predict(data[[\"lat\", \"lon\"]].to_numpy()))\n",
    "        )\n",
    "        metrics[\"davies_bouldin\"].append(\n",
    "            davies_bouldin_score(data, model.predict(data[[\"lat\", \"lon\"]].to_numpy()))\n",
    "        )\n",
    "        metrics[\"n_clusters\"].append(\n",
    "            len(np.unique(model.predict(data[[\"lat\", \"lon\"]].to_numpy())))\n",
    "        )\n",
    "    else:\n",
    "        model.fit(data[[\"lat\", \"lon\"]])\n",
    "        data[f\"{model_name}_cluster\"] = model.labels_\n",
    "        # metrics[\"silhouette\"].append(silhouette_score(data, model.labels_))\n",
    "        # metrics[\"davies_bouldin\"].append(davies_bouldin_score(data, model.labels_))\n",
    "        metrics[\"n_clusters\"].append(len(np.unique(model.labels_)))\n",
    "    metrics[\"time\"].append(time.time() - start_time)\n",
    "\n",
    "    metrics[\"model\"].append(model_name)\n",
    "\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "display(metrics)\n",
    "\n",
    "data[[\"lat\", \"lon\"]] = scaler.inverse_transform(data[[\"lat\", \"lon\"]])\n",
    "\n",
    "# Plot the results in a map that shows the contours of the clusters and of Colombia\n",
    "for model_name, model in models.items():\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lat=data[\"lat\"],\n",
    "            lon=data[\"lon\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=10, color=data[f\"{model_name}_cluster\"]),\n",
    "            text=data.index,\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"Clusters {model_name}\",\n",
    "        mapbox=dict(\n",
    "            style=\"carto-positron\",\n",
    "            center=dict(lat=4.5709, lon=-74.2973),\n",
    "            zoom=3,\n",
    "        ),\n",
    "    )\n",
    "    # fig.show()\n",
    "    fig.write_html(f\"html/5. results - {model_name}.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOM_cluster\n",
       "0     83\n",
       "1    110\n",
       "2     81\n",
       "3     99\n",
       "4     43\n",
       "5    142\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KMeans_cluster\n",
       "0    108\n",
       "1     86\n",
       "2    119\n",
       "3    128\n",
       "4     18\n",
       "5     99\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Agglomerative_cluster\n",
       "0    166\n",
       "1     21\n",
       "2    114\n",
       "3     76\n",
       "4     99\n",
       "5     82\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DBSCAN_cluster\n",
       "-1     153\n",
       " 0      33\n",
       " 1     183\n",
       " 2      82\n",
       " 3      24\n",
       " 4      12\n",
       " 5      25\n",
       " 6       7\n",
       " 7       7\n",
       " 8      13\n",
       " 9       7\n",
       " 10      6\n",
       " 11      6\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(data)\n",
    "# Size of the clusters for each model\n",
    "for model_name in models.keys():\n",
    "    display(data.groupby(f\"{model_name}_cluster\").size())\n",
    "\n",
    "# add the information to the population dataframe\n",
    "for model_name in models.keys():\n",
    "    population[f\"cluster {model_name}\"] = data[f\"{model_name}_cluster\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (558, 5)\n",
      "cluster 3: 19 municipalities\n",
      "cluster 4: 15 municipalities\n",
      "cluster 5: 9 municipalities\n",
      "cluster 6: 24 municipalities\n",
      "cluster 9: 20 municipalities\n",
      "cluster 11: 1 municipalities\n",
      "cluster 13: 14 municipalities\n",
      "cluster 14: 5 municipalities\n",
      "cluster 17: 7 municipalities\n",
      "cluster 20: 6 municipalities\n",
      "cluster 21: 12 municipalities\n",
      "cluster 23: 2 municipalities\n",
      "cluster 24: 17 municipalities\n",
      "cluster 26: 20 municipalities\n",
      "cluster 27: 23 municipalities\n",
      "cluster 28: 15 municipalities\n",
      "cluster 29: 17 municipalities\n",
      "cluster 30: 18 municipalities\n",
      "cluster 31: 14 municipalities\n",
      "cluster 32: 22 municipalities\n",
      "cluster 33: 17 municipalities\n",
      "cluster 34: 15 municipalities\n",
      "cluster 35: 12 municipalities\n",
      "cluster 36: 23 municipalities\n",
      "cluster 37: 16 municipalities\n",
      "cluster 39: 13 municipalities\n",
      "cluster 40: 16 municipalities\n",
      "cluster 42: 5 municipalities\n",
      "cluster 43: 25 municipalities\n",
      "cluster 44: 16 municipalities\n",
      "cluster 45: 17 municipalities\n",
      "cluster 46: 16 municipalities\n",
      "cluster 47: 19 municipalities\n",
      "cluster 48: 10 municipalities\n",
      "cluster 49: 13 municipalities\n",
      "cluster 50: 14 municipalities\n",
      "cluster 51: 15 municipalities\n",
      "cluster 52: 16 municipalities\n",
      "558\n",
      "----- Cluster 3 ----- || size (19, 19) || Current time: 1716269359.8858423\n",
      "Status: Optimal\n",
      "Objective function: 17127801.368411362\n",
      "Number of facilities: 5.0\n",
      "Elapsed time: 1.64 s\n",
      "----- Cluster 4 ----- || size (15, 15) || Current time: 1716269361.6028914\n",
      "Status: Optimal\n",
      "Objective function: 25407722.118285514\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 0.86 s\n",
      "----- Cluster 5 ----- || size (9, 9) || Current time: 1716269362.509219\n",
      "Status: Optimal\n",
      "Objective function: 8412307.665798297\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.07 s\n",
      "----- Cluster 6 ----- || size (24, 24) || Current time: 1716269362.639097\n",
      "Status: Optimal\n",
      "Objective function: 11498328.808484295\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.06 s\n",
      "----- Cluster 9 ----- || size (20, 20) || Current time: 1716269362.7920732\n",
      "Status: Optimal\n",
      "Objective function: 24479536.358147252\n",
      "Number of facilities: 6.0\n",
      "Elapsed time: 5.62 s\n",
      "----- Cluster 11 ----- || size (1, 1) || Current time: 1716269368.5785365\n",
      "Status: Optimal\n",
      "Objective function: 3111202.75\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.00 s\n",
      "----- Cluster 13 ----- || size (14, 14) || Current time: 1716269368.6121957\n",
      "Status: Optimal\n",
      "Objective function: 19302377.4188\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.55 s\n",
      "----- Cluster 14 ----- || size (5, 5) || Current time: 1716269369.2028856\n",
      "Status: Optimal\n",
      "Objective function: 7433789.687999999\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.01 s\n",
      "----- Cluster 17 ----- || size (7, 7) || Current time: 1716269369.2384174\n",
      "Status: Optimal\n",
      "Objective function: 6272805.2844\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.01 s\n",
      "----- Cluster 20 ----- || size (6, 6) || Current time: 1716269369.2771184\n",
      "Status: Optimal\n",
      "Objective function: 9202342.329599999\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.01 s\n",
      "----- Cluster 21 ----- || size (12, 12) || Current time: 1716269369.3217611\n",
      "Status: Optimal\n",
      "Objective function: 8818063.8632\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.06 s\n",
      "----- Cluster 23 ----- || size (2, 2) || Current time: 1716269369.4185627\n",
      "Status: Optimal\n",
      "Objective function: 3111202.75\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.01 s\n",
      "----- Cluster 24 ----- || size (17, 17) || Current time: 1716269369.4660435\n",
      "Status: Optimal\n",
      "Objective function: 13442090.171640791\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 0.09 s\n",
      "----- Cluster 26 ----- || size (20, 20) || Current time: 1716269369.6198003\n",
      "Status: Optimal\n",
      "Objective function: 9367676.874400001\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 1.62 s\n",
      "----- Cluster 27 ----- || size (23, 23) || Current time: 1716269371.3148966\n",
      "Status: Optimal\n",
      "Objective function: 16914337.337676663\n",
      "Number of facilities: 4.0\n",
      "Elapsed time: 0.91 s\n",
      "----- Cluster 28 ----- || size (15, 15) || Current time: 1716269372.3038187\n",
      "Status: Optimal\n",
      "Objective function: 9332166.489439389\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.48 s\n",
      "----- Cluster 29 ----- || size (17, 17) || Current time: 1716269372.8374424\n",
      "Status: Optimal\n",
      "Objective function: 56326899.472799994\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.12 s\n",
      "----- Cluster 30 ----- || size (18, 18) || Current time: 1716269373.010514\n",
      "Status: Optimal\n",
      "Objective function: 28628628.57800001\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 3.76 s\n",
      "----- Cluster 31 ----- || size (14, 14) || Current time: 1716269376.8295357\n",
      "Status: Optimal\n",
      "Objective function: 33415789.511933353\n",
      "Number of facilities: 10.0\n",
      "Elapsed time: 0.90 s\n",
      "----- Cluster 32 ----- || size (22, 22) || Current time: 1716269377.7896335\n",
      "Status: Optimal\n",
      "Objective function: 10095815.968766415\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.12 s\n",
      "----- Cluster 33 ----- || size (17, 17) || Current time: 1716269377.9729896\n",
      "Status: Optimal\n",
      "Objective function: 8560794.9496\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.02 s\n",
      "----- Cluster 34 ----- || size (15, 15) || Current time: 1716269378.047123\n",
      "Status: Optimal\n",
      "Objective function: 11763321.75113704\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.76 s\n",
      "----- Cluster 35 ----- || size (12, 12) || Current time: 1716269378.8538265\n",
      "Status: Optimal\n",
      "Objective function: 8631545.12772588\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.39 s\n",
      "----- Cluster 36 ----- || size (23, 23) || Current time: 1716269379.308322\n",
      "Status: Optimal\n",
      "Objective function: 19746595.623199996\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 3.05 s\n",
      "----- Cluster 37 ----- || size (16, 16) || Current time: 1716269382.4221435\n",
      "Status: Optimal\n",
      "Objective function: 18724228.466311816\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 1.07 s\n",
      "----- Cluster 39 ----- || size (13, 13) || Current time: 1716269383.5387752\n",
      "Status: Optimal\n",
      "Objective function: 8028654.503600001\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.67 s\n",
      "----- Cluster 40 ----- || size (16, 16) || Current time: 1716269384.2511542\n",
      "Status: Optimal\n",
      "Objective function: 8729816.0512\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.64 s\n",
      "----- Cluster 42 ----- || size (5, 5) || Current time: 1716269384.9289896\n",
      "Status: Optimal\n",
      "Objective function: 6911099.778\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.01 s\n",
      "----- Cluster 43 ----- || size (25, 25) || Current time: 1716269385.011093\n",
      "Status: Optimal\n",
      "Objective function: 15568018.838161392\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 4.26 s\n",
      "----- Cluster 44 ----- || size (16, 16) || Current time: 1716269389.3691354\n",
      "Status: Optimal\n",
      "Objective function: 20371849.39763699\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 0.23 s\n",
      "----- Cluster 45 ----- || size (17, 17) || Current time: 1716269389.6532269\n",
      "Status: Optimal\n",
      "Objective function: 12563622.362038618\n",
      "Number of facilities: 3.0\n",
      "Elapsed time: 1.19 s\n",
      "----- Cluster 46 ----- || size (16, 16) || Current time: 1716269390.9083943\n",
      "Status: Optimal\n",
      "Objective function: 8815812.001600001\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.92 s\n",
      "----- Cluster 47 ----- || size (19, 19) || Current time: 1716269391.908597\n",
      "Status: Optimal\n",
      "Objective function: 5460771.7299999995\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.03 s\n",
      "----- Cluster 48 ----- || size (10, 10) || Current time: 1716269391.985758\n",
      "Status: Optimal\n",
      "Objective function: 7334040.309200001\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.37 s\n",
      "----- Cluster 49 ----- || size (13, 13) || Current time: 1716269392.3942256\n",
      "Status: Optimal\n",
      "Objective function: 21406497.77\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.06 s\n",
      "----- Cluster 50 ----- || size (14, 14) || Current time: 1716269392.4936125\n",
      "Status: Optimal\n",
      "Objective function: 7864074.8544\n",
      "Number of facilities: 1.0\n",
      "Elapsed time: 0.03 s\n",
      "----- Cluster 51 ----- || size (15, 15) || Current time: 1716269392.566893\n",
      "Status: Optimal\n",
      "Objective function: 8996159.4056\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 0.82 s\n",
      "----- Cluster 52 ----- || size (16, 16) || Current time: 1716269393.4384832\n",
      "Status: Optimal\n",
      "Objective function: 8227109.310400001\n",
      "Number of facilities: 2.0\n",
      "Elapsed time: 1.49 s\n",
      "Solution time: 35.10 s\n",
      "Objective function: 529404897.03759503\n"
     ]
    }
   ],
   "source": [
    "data = population.copy()[\n",
    "    [\n",
    "        \"demand\",\n",
    "        \"_satisfied\",\n",
    "        \"_cost\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "    ]\n",
    "]\n",
    "dist = distance.copy()\n",
    "print(f\"size: {data.shape}\")\n",
    "\n",
    "# The algorithm follows the following steps:\n",
    "# 1. Split the data into clusters\n",
    "# 2. for each clusters, check if the size is greater than 1 and lower than max_chunk_size\n",
    "# 2.2. If the cluster size is greater than max_chunk_size, split the cluster into int(cluster_size/max_chunk_size + 1) clusters until all clusters have a size lower than max_chunk_size\n",
    "# 3. For each cluster, check if the CFLP is feasible\n",
    "# 3.1. If the CFLP is not feasible, add warehouses until the CFLP is feasible# 4.2.\n",
    "# 3.2. If the CFLP is feasible, run the CFLP\n",
    "# 4. Create a new dataframe with the results of the CFLP\n",
    "# 5. plot the results of the CFLP\n",
    "# 6. Save the results of the CFLP\n",
    "\n",
    "\n",
    "max_chunk_size = 25\n",
    "start_n_clusters = int(proposed_k)\n",
    "randomSeed = np.random.randint(0, 1000)\n",
    "model = KMeans(n_clusters=start_n_clusters, random_state=randomSeed)\n",
    "\n",
    "# 1. Split the data into clusters\n",
    "model.fit(data[[\"lat\", \"lon\"]])\n",
    "data[\"cluster\"] = model.labels_\n",
    "\n",
    "# 2. for each clusters, check if the size is greater than 1 and lower than max_chunk_size\n",
    "if data.groupby(\"cluster\").size().max() > max_chunk_size:\n",
    "    while data.groupby(\"cluster\").size().max() > max_chunk_size:\n",
    "        for cluster in data.groupby(\"cluster\"):\n",
    "            if cluster[1].shape[0] > max_chunk_size:\n",
    "                n_clusters = int(cluster[1].shape[0] / max_chunk_size) + 1\n",
    "                model = KMeans(n_clusters=n_clusters, random_state=randomSeed)\n",
    "                model.fit(cluster[1][[\"lat\", \"lon\"]])\n",
    "                data.loc[cluster[1].index, \"cluster\"] = (\n",
    "                    model.labels_ + data[\"cluster\"].max() + 1\n",
    "                )\n",
    "for cluster in data.groupby(\"cluster\"):\n",
    "    print(f\"cluster {cluster[0]}: {cluster[1].shape[0]} municipalities\")\n",
    "print(data.groupby(\"cluster\").size().sum())\n",
    "# 3. For each cluster, check if the CFLP is feasible\n",
    "for cluster in data.groupby(\"cluster\"):\n",
    "    if cluster[1][\"demand\"].sum() > cluster[1][\"_satisfied\"].sum():\n",
    "        print(f\"cluster {cluster[0]}: CFLP not feasible\")\n",
    "        print(f\"Demand: {cluster[1]['demand'].sum()}\")\n",
    "        print(f\"Satisfied: {cluster[1]['_satisfied'].sum()}\")\n",
    "    # else:\n",
    "    #     print(f\"cluster {cluster[0]}: CFLP feasible\")\n",
    "    #     print(f\"Demand: {cluster[1]['demand'].sum()}\")\n",
    "    #     print(f\"Satisfied: {cluster[1]['_satisfied'].sum()}\")\n",
    "\n",
    "# 3.1. If the CFLP is not feasible, add warehouses until the CFLP is feasible\n",
    "# 3.2. If the CFLP is feasible, run the CFLP\n",
    "start_time = time.time()\n",
    "solutions_y = {}\n",
    "solutions_x = {}\n",
    "objectives = {}\n",
    "\n",
    "clusters_to_skip = []\n",
    "for cluster in data.groupby(\"cluster\"):\n",
    "    if cluster[0] in clusters_to_skip:\n",
    "        continue\n",
    "    h_i = cluster[1][\"demand\"].values  # demand of customer i\n",
    "    c_ij = (\n",
    "        dist.loc[cluster[1].index, cluster[1].index] * transport_cost_per_ton_per_km\n",
    "    ).values  # distance between customer i and j\n",
    "    f_j = cluster[1][\"_cost\"].values.tolist()  # fixed cost to open a facility at site j\n",
    "    v_j = cluster[1][\n",
    "        \"_satisfied\"\n",
    "    ].values  # maximum capacity of facility j or the amount of capacity that it can be satisfied\n",
    "\n",
    "    # Inside the loop, for testing we will work with the last group\n",
    "    ## Create the variables\n",
    "    I = range(len(h_i))\n",
    "    J = range(len(f_j))\n",
    "    x_j = pulp.LpVariable.dicts(\"x\", J, cat=\"Binary\")\n",
    "    y_ij = pulp.LpVariable.dicts(\n",
    "        \"y\", ((i, j) for i in I for j in J), lowBound=0, upBound=1, cat=\"Continuous\"\n",
    "    )\n",
    "    ## Create the model\n",
    "    model = pulp.LpProblem(\"CFLP\", pulp.LpMinimize)\n",
    "    ## Objective function\n",
    "    model += (\n",
    "        pulp.lpSum(f_j[j] * x_j[j] for j in J)\n",
    "        + pulp.lpSum(c_ij[i][j] * y_ij[(i, j)] for i in I for j in J),\n",
    "        \"Total cost\",\n",
    "    )\n",
    "    ## Constraints\n",
    "    for i in I:\n",
    "        model += pulp.lpSum(y_ij[(i, j)] for j in J) == 1, f\"Population demand {i}\"\n",
    "    for j in J:\n",
    "        for i in I:\n",
    "            model += y_ij[(i, j)] <= x_j[j], f\"Facility assignment {i} {j}\"\n",
    "    for j in J:\n",
    "        model += (\n",
    "            pulp.lpSum(h_i[i] * y_ij[(i, j)] for i in I) <= v_j[j],\n",
    "            f\"Facility capacity {j}\",\n",
    "        )\n",
    "    ## Solve the model\n",
    "    print(\n",
    "        f\"----- Cluster {cluster[0]} ----- || size {c_ij.shape} || Current time: {time.time()}\"\n",
    "    )\n",
    "\n",
    "    # Save the parameters to an excel file where each sheet is parameter h, c, f, v\n",
    "    df_h = pd.DataFrame(h_i, columns=[\"demand\"], index=cluster[1].index)\n",
    "    df_c = pd.DataFrame(c_ij, columns=cluster[1].index, index=cluster[1].index)\n",
    "    df_f = pd.DataFrame(f_j, columns=[\"cost\"], index=cluster[1].index)\n",
    "    df_v = pd.DataFrame(v_j, columns=[\"capacity\"], index=cluster[1].index)\n",
    "    with pd.ExcelWriter(f\"parameters/cluster_{cluster[0]}.xlsx\") as writer:\n",
    "        df_h.to_excel(writer, sheet_name=\"demand\")\n",
    "        df_c.to_excel(writer, sheet_name=\"distance\")\n",
    "        df_f.to_excel(writer, sheet_name=\"cost\")\n",
    "        df_v.to_excel(writer, sheet_name=\"capacity\")\n",
    "    del df_h, df_c, df_f, df_v\n",
    "    _cluster_start_time = time.time()\n",
    "    model.solve(\n",
    "        solver=pulp.PULP_CBC_CMD(\n",
    "            logPath=f\"logs/5 lp - solution _cluster {cluster[0]}.log\",\n",
    "            msg=False,\n",
    "            timeLimit=10 * 60,\n",
    "            threads=os.cpu_count(),\n",
    "        )\n",
    "    )\n",
    "    ## Results\n",
    "    print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
    "    print(f\"Objective function: {pulp.value(model.objective)}\")\n",
    "    print(f\"Number of facilities: {pulp.value(pulp.lpSum(x_j[j] for j in J))}\")\n",
    "    print(f\"Elapsed time: {time.time() - _cluster_start_time:.2f} s\")\n",
    "    ## Save the solution\n",
    "    df_y = pd.DataFrame(\n",
    "        [[pulp.value(y_ij[(i, j)]) for j in J] for i in I],\n",
    "        columns=cluster[1].index,\n",
    "        index=cluster[1].index,\n",
    "    )\n",
    "    df_x = pd.DataFrame(\n",
    "        [pulp.value(x_j[j]) for j in J], columns=[\"open\"], index=cluster[1].index\n",
    "    )\n",
    "    with pd.ExcelWriter(f\"solutions/cluster_{cluster[0]}.xlsx\") as writer:\n",
    "        df_y.to_excel(writer, sheet_name=\"Y\")\n",
    "        df_x.to_excel(writer, sheet_name=\"X\")\n",
    "\n",
    "    solutions_y[cluster[0]] = df_y\n",
    "    solutions_x[cluster[0]] = df_x\n",
    "    objectives[cluster[0]] = pulp.value(model.objective)\n",
    "\n",
    "    del model, x_j, y_ij, I, J, h_i, c_ij, f_j, v_j, df_y, df_x\n",
    "    # End of the loop\n",
    "\n",
    "print(f\"Solution time: {time.time() - start_time:.2f} s\")\n",
    "print(f\"Objective function: {sum(objectives.values())}\")\n",
    "\n",
    "# 4. Create a new dataframe with the results of the CFLP\n",
    "\n",
    "\n",
    "# 5. plot the results of the CFLP in a map with the contours of Colombia\n",
    "fig = go.Figure()\n",
    "## Add the municipalities and the color with the cluster to which they belong\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        lat=data[\"lat\"],\n",
    "        lon=data[\"lon\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=11, color=data[\"cluster\"], colorscale=\"twilight\"),\n",
    "        text=data.index,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add the arrows that show the amount of the demand that each facility satisfies\n",
    "for cluster in solutions_y.keys():\n",
    "    for i in solutions_y[cluster].index:\n",
    "        for j in solutions_y[cluster].columns:\n",
    "            fig.add_trace(\n",
    "                go.Scattermapbox(\n",
    "                    lat=[data.loc[i, \"lat\"], data.loc[j, \"lat\"]],\n",
    "                    lon=[data.loc[i, \"lon\"], data.loc[j, \"lon\"]],\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=solutions_y[cluster].loc[i, j] * 5, color=\"orange\"),\n",
    "                    opacity=solutions_y[cluster].loc[i, j],\n",
    "                )\n",
    "            )\n",
    "fig.update_layout(\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        center=dict(lon=-74, lat=4),\n",
    "        zoom=4,\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "# Add the Open facilitys\n",
    "for cluster in solutions_x.keys():\n",
    "    for i in solutions_x[cluster].index:\n",
    "        if solutions_x[cluster].loc[i, \"open\"] == 1:\n",
    "            fig.add_trace(\n",
    "                go.Scattermapbox(\n",
    "                    lat=[data.loc[i, \"lat\"]],\n",
    "                    lon=[data.loc[i, \"lon\"]],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=8, color=\"red\"),\n",
    "                    text=i,\n",
    "                )\n",
    "            )\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the html\n",
    "fig.write_html(\"solutions/figure.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
