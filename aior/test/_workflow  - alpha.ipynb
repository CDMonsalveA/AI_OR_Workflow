{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncapacitated Facility Location Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Personal modules\n",
    "from lp.uflp import UFLP\n",
    "from lp.cflp import CFLP\n",
    "from lp.telp import TELP\n",
    "\n",
    "# Plotting modules\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Linear programming modules\n",
    "import pulp\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# == Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# == Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# == Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# == Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# == Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      "    food_per_person_per_day: 0.00087617 \n",
      "    transport_cost_per_ton_per_km: 3364.0\n",
      "\n",
      "data information: \n",
      "    population: (1117, 71) \n",
      "    distance: (1117, 1117) \n",
      "    warehouses: \n",
      "    Type  capacity_ton        cost\n",
      "0     1          1074   731159925\n",
      "1     2          2418  1129212606\n",
      "2     3          9672  4516850424 \n",
      "\n",
      "population memory usage: 0.61 MB\n",
      "distance memory usage: 9.56 MB\n",
      "warehouses memory usage: 0.00 MB\n",
      "Elapsed time: 0.44 s\n"
     ]
    }
   ],
   "source": [
    "# import the data and parameters and check the data\n",
    "\n",
    "data_path = \"data/\"\n",
    "start_time = time.time()\n",
    "# ====Parameters==== #\n",
    "parameters = pd.read_csv(os.path.join(data_path, \"parametros.csv\"))\n",
    "# 1. food_per_person_per_day in tons per day\n",
    "food_per_person_per_day = float(\n",
    "    parameters.loc[parameters[\"parametro\"] == \"comida_por_persona_en_toneladas\"].values[\n",
    "        0\n",
    "    ][1]\n",
    ")\n",
    "# 2. transport_cost_per_ton_per_km in COP per ton per km\n",
    "transport_cost_per_ton_per_km = float(\n",
    "    parameters.loc[\n",
    "        parameters[\"parametro\"] == \"costo_de_transporte_por_tonelada_por_kilomentro\"\n",
    "    ].values[0][1]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"parameters: \\n    food_per_person_per_day: {food_per_person_per_day} \\n    transport_cost_per_ton_per_km: {transport_cost_per_ton_per_km}\\n\"\n",
    ")\n",
    "# ====Parameters==== #\n",
    "\n",
    "# ====importData==== #\n",
    "# 1. population, from data/municipios_procesado.csv\n",
    "population = pd.read_csv(\n",
    "    os.path.join(data_path, \"municipios_procesado.csv\"), index_col=3\n",
    ")\n",
    "# 2. distance, from data/distance_matrix_final.csv\n",
    "distance = pd.read_csv(\n",
    "    os.path.join(data_path, \"distance_matrix_final.csv\"), index_col=0\n",
    ")\n",
    "# 3. warehouses, from data/almacenes.csv\n",
    "warehouses = pd.read_csv(os.path.join(data_path, \"almacenes.csv\"))\n",
    "# ====importData==== #\n",
    "\n",
    "# ====DataProcessing===== #\n",
    "# fill the nan values in population with the minimum '2024' from the departamento of Chocó for the columns 22:\n",
    "population.loc[population.isna().any(axis=1), population.columns[18:]] = (\n",
    "    population[\n",
    "        population[\"2024\"]\n",
    "        == population.loc[population[\"departamento\"] == \"Chocó\"][\"2024\"].min()\n",
    "    ]\n",
    "    .iloc[0, 18:]\n",
    "    .values\n",
    ")\n",
    "# drop the municipalities with nan values in the first column of the distance matrix\n",
    "distance = distance.dropna(subset=[distance.columns[0]], axis=0)\n",
    "distance = distance.dropna(subset=[distance.index[0]], axis=1)\n",
    "# select only the rows in population dpmp that the index is in distance\n",
    "population = population.loc[distance.index]\n",
    "# turn the columns of distance into integers\n",
    "distance.columns = distance.columns.astype(int)\n",
    "print(\n",
    "    f\"data information: \\n    population: {population.shape} \\n    distance: {distance.shape} \\n    warehouses: \\n {warehouses} \\n\"\n",
    ")\n",
    "# ====DataProcessing===== #\n",
    "\n",
    "# ====DataInformation==== #\n",
    "# Memory usage of the data\n",
    "print(f\"population memory usage: {population.memory_usage().sum()/1024**2:.2f} MB\")\n",
    "print(f\"distance memory usage: {distance.memory_usage().sum()/1024**2:.2f} MB\")\n",
    "print(f\"warehouses memory usage: {warehouses.memory_usage().sum()/1024**2:.2f} MB\")\n",
    "# ====DataInformation==== #\n",
    "\n",
    "# ====DataChecking==== #\n",
    "# Test to the data if needed\n",
    "# ====DataChecking==== #\n",
    "print(f\"Elapsed time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Demand Forecast\n",
    "\n",
    "we are using the data from the population dataset that has the colombian census information since 1985 to 2035, the current year is 2024 and the last census was performed in 2018, the data was taken on december 2023 from the DANE web page.\n",
    "\n",
    "First we need to check the current forecast, then use 4 ML algorithms and Deep Learning to create a new model. The Machine Learning algorithms are:\n",
    "- Multiple Linear Regression.\n",
    "- Regression Tree.\n",
    "- Support Vector Machine.\n",
    "- Random Forest Regression.\n",
    "\n",
    "Then, we need the Mean Absolute Error (MAE) to compare the models. The best model will be used to forecast the demand for the next 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression: 2.42 s\n",
      "    Mean Absolute Error: 0.428457750684778\n",
      "    Mean Squared Error: 0.3664370666800922\n",
      "    R2 Score: 0.5860169997999521\n",
      "Regression Tree: 1.92 s\n",
      "    Mean Absolute Error: 0.09093062070801274\n",
      "    Mean Squared Error: 0.032517679104043365\n",
      "    R2 Score: 0.9672813069578106\n",
      "Support Vector Machine: 2.01 s\n",
      "    Mean Absolute Error: 0.10992893224062007\n",
      "    Mean Squared Error: 0.05873704491266884\n",
      "    R2 Score: 0.9431877181416908\n",
      "Random Forest Regression: 113.65 s\n",
      "    Mean Absolute Error: 0.058143409802692725\n",
      "    Mean Squared Error: 0.01980284856886718\n",
      "    R2 Score: 0.9805442499502212\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Demand Forecast\n",
    "\n",
    "# 1. Demand Forecast\n",
    "data = population.copy().iloc[:, 20:]\n",
    "data = data.transpose()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Multiple Linear Regression\": LinearRegression(),\n",
    "    \"Regression Tree\": DecisionTreeRegressor(\n",
    "        max_depth=10, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "    \"Support Vector Machine\": SVR(C=1.0, kernel=\"rbf\", gamma=\"scale\"),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float(\"-inf\")\n",
    "results = {}\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    mean_absolute_errors = []\n",
    "    mean_squared_errors = []\n",
    "    r2_scores = []\n",
    "\n",
    "    # For each column in the data\n",
    "    for column in data.columns:\n",
    "        model.fit(train.index.values.reshape(-1, 1), train[column])\n",
    "        predictions = model.predict(test.index.values.reshape(-1, 1))\n",
    "        mean_absolute_errors.append(mean_absolute_error(test[column], predictions))\n",
    "        mean_squared_errors.append(mean_squared_error(test[column], predictions))\n",
    "        r2_scores.append(r2_score(test[column], predictions))\n",
    "\n",
    "    avg_r2_score = np.mean(r2_scores)\n",
    "    results[model_name] = {\n",
    "        \"time\": time.time() - start_time,\n",
    "        \"mean_absolute_error\": np.mean(mean_absolute_errors),\n",
    "        \"mean_squared_error\": np.mean(mean_squared_errors),\n",
    "        \"r2_score\": avg_r2_score,\n",
    "    }\n",
    "\n",
    "    if avg_r2_score > best_score:\n",
    "        best_score = avg_r2_score\n",
    "        best_model = model\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: {metrics['time']:.2f} s\")\n",
    "    print(f\"    Mean Absolute Error: {metrics['mean_absolute_error']}\")\n",
    "    print(f\"    Mean Squared Error: {metrics['mean_squared_error']}\")\n",
    "    print(f\"    R2 Score: {metrics['r2_score']}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set facility types\n",
    "\n",
    "We have 3 types of facilities:\n",
    "- Type 1: Small facility.\n",
    "- Type 2: Medium facility.\n",
    "- Type 3: Large facility.\n",
    "\n",
    "for each facility type we have the following information:\n",
    "- Fixed cost.\n",
    "- Variable cost.\n",
    "\n",
    "The proposal is to use a mathematical model to determine the number of facilities of each type to minimize the total cost, in order to satisfy the demand. and be able to train a classifier to predict the type of facility that will be needed for the hole country.\n",
    "\n",
    "### Model\n",
    "\n",
    "#### Sets\n",
    "- $I$: Set of municipalities.\n",
    "- $J$: Types of facilities.\n",
    "\n",
    "#### Parameters\n",
    "- $c_{j}$: Capacity of facility type $j$.\n",
    "- $f_{j}$: Fixed cost of facility type $j$.\n",
    "\n",
    "- $p_{i}$: Population of municipality $i$.\n",
    "- $N$: Food Demand per capita in Tonnes.\n",
    "- $d_{i}$: Demand of municipality $i$ = $p_{i} * N$.\n",
    "- $r_{i}$: department aggregation of population of municipality $i$.\n",
    "- $\\lambda_{i}$: Multiplier of demand of municipality based on its department population.$\n",
    "\n",
    "#### Decision Variables\n",
    "- $x_{ij}$: Number of facilities of type $j$ in municipality $i$.\n",
    "\n",
    "#### Objective Function\n",
    "- Minimize the total cost of the facilities.\n",
    "\n",
    "$$ \\text{Min} \\sum_{i \\in I} \\sum_{j \\in J} f_{j} * x_{ij} $$\n",
    "\n",
    "#### Constraints\n",
    "\n",
    "- Demand constraint: The demand of municipality $i$ must be satisfied.\n",
    "\n",
    "$$ \\sum_{j \\in J} x_{ij} * c_{j} \\geq d_{i} * \\lambda_{i} \\quad \\forall i \\in I $$\n",
    "\n",
    "- (optional) General capacity:\n",
    "\n",
    "$$ \\sum_{i \\in I} \\sum_{j \\in J} x_{ij} * c_{j} \\leq \\sum_{i \\in I} d_{i} * \\lambda_{i} $$\n",
    "\n",
    "- Non-negativity:\n",
    "\n",
    "$$ x_{ij} \\geq 0 \\quad \\forall i \\in I, \\forall j \\in J $$\n",
    "\n",
    "- Integer:\n",
    "\n",
    "$$ x_{ij} \\in \\mathbb{Z} \\quad \\forall i \\in I, \\forall j \\in J $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Objective function: 811097283420.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([(1.0, 0.0, 0.0), (0.0, 0.0, 1.0), (0.0, 3.0, 0.0),\n",
       "       (0.0, 31.0, 0.0), (3.0, 0.0, 0.0), (0.0, 1.0, 0.0),\n",
       "       (0.0, 6.0, 0.0), (0.0, 9.0, 0.0), (0.0, 2.0, 0.0), (0.0, 5.0, 0.0),\n",
       "       (0.0, 10.0, 0.0)], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facility 0</th>\n",
       "      <th>Facility 1</th>\n",
       "      <th>Facility 2</th>\n",
       "      <th>demand</th>\n",
       "      <th>satisfied</th>\n",
       "      <th>cost</th>\n",
       "      <th>comb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpmp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25781</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.932040</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47318</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186.166849</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.635369</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25258</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.793877</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19142</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.514411</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50590</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.834284</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47960</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.673618</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.054387</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17486</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.746764</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85250</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.405591</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>731159925.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Facility 0  Facility 1  Facility 2      demand  satisfied         cost  \\\n",
       "dpmp                                                                            \n",
       "25781         1.0         0.0         0.0   43.932040     1074.0  731159925.0   \n",
       "47318         1.0         0.0         0.0  186.166849     1074.0  731159925.0   \n",
       "27073         1.0         0.0         0.0   72.635369     1074.0  731159925.0   \n",
       "25258         1.0         0.0         0.0   33.793877     1074.0  731159925.0   \n",
       "19142         1.0         0.0         0.0  193.514411     1074.0  731159925.0   \n",
       "...           ...         ...         ...         ...        ...          ...   \n",
       "50590         1.0         0.0         0.0   84.834284     1074.0  731159925.0   \n",
       "47960         1.0         0.0         0.0   67.673618     1074.0  731159925.0   \n",
       "5147          1.0         0.0         0.0  320.054387     1074.0  731159925.0   \n",
       "17486         1.0         0.0         0.0  132.746764     1074.0  731159925.0   \n",
       "85250         1.0         0.0         0.0  251.405591     1074.0  731159925.0   \n",
       "\n",
       "                  comb  \n",
       "dpmp                    \n",
       "25781  (1.0, 0.0, 0.0)  \n",
       "47318  (1.0, 0.0, 0.0)  \n",
       "27073  (1.0, 0.0, 0.0)  \n",
       "25258  (1.0, 0.0, 0.0)  \n",
       "19142  (1.0, 0.0, 0.0)  \n",
       "...                ...  \n",
       "50590  (1.0, 0.0, 0.0)  \n",
       "47960  (1.0, 0.0, 0.0)  \n",
       "5147   (1.0, 0.0, 0.0)  \n",
       "17486  (1.0, 0.0, 0.0)  \n",
       "85250  (1.0, 0.0, 0.0)  \n",
       "\n",
       "[949 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization of the model\n",
    "p = population[\"2024\"].sample(frac=0.85, random_state=5)\n",
    "\n",
    "# ====Parameters==== #\n",
    "c_j = warehouses[\"capacity_ton\"].values.astype(float)\n",
    "f_j = warehouses[\"cost\"].values.astype(float)\n",
    "\n",
    "\n",
    "p_i = p.values.astype(int)\n",
    "n = food_per_person_per_day * 7\n",
    "d_i = p_i * n\n",
    "# Lambda = 2 for the top 32 municipalities, 1 for the rest\n",
    "lambda_i = np.ones(len(p_i)) * 1.1\n",
    "lambda_i[np.argsort(p_i)[-32:]] = 1.5\n",
    "# ====Parameters==== #\n",
    "\n",
    "\n",
    "# Decision variables: $x_{ij}$\n",
    "I = range(len(p_i))\n",
    "J = range(len(c_j))\n",
    "model = pulp.LpProblem(\"UFLP\", pulp.LpMinimize)\n",
    "x = pulp.LpVariable.dicts(\n",
    "    \"x\", ((i, j) for i in I for j in J), lowBound=0, cat=\"Integer\"\n",
    ")\n",
    "y = pulp.LpVariable.dicts(\"y\", ((i, j) for i in I for j in J), cat=\"Binary\")\n",
    "# Objective function\n",
    "model += (\n",
    "    pulp.lpSum(f_j[j] * x[(i, j)] for i in I for j in J),\n",
    "    \"Total cost of the facilities\",\n",
    ")\n",
    "# Constraints\n",
    "for i in I:\n",
    "    model += (\n",
    "        pulp.lpSum(c_j[j] * x[(i, j)] for j in J) >= d_i[i] * lambda_i[i],\n",
    "        f\"Population demand {i}\",\n",
    "    )\n",
    "    model += (\n",
    "        pulp.lpSum(x[(i, j)] for j in J) >= 1,\n",
    "        f\"Facility assignment {i}\",\n",
    "    )\n",
    "    model += (\n",
    "        pulp.lpSum(y[(i, j)] for j in J) == 1,\n",
    "        f\"Faacility assignment __ {i}\",\n",
    "    )\n",
    "    for j in J:\n",
    "        model += (\n",
    "            x[(i, j)] <= 100 * y[(i, j)],\n",
    "            f\"Fsacility assignment _ {i} _ {j}\",\n",
    "        )\n",
    "\n",
    "model += pulp.lpSum(x[(i, j)] * c_j[j] for i in I for j in J) >= pulp.lpSum(\n",
    "    d_i[i] * lambda_i[i] for i in I\n",
    ")\n",
    "\n",
    "\n",
    "# Solve the model\n",
    "model.solve()\n",
    "# Results\n",
    "print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
    "print(f\"Objective function: {pulp.value(model.objective)}\")\n",
    "df = pd.DataFrame(\n",
    "    [[pulp.value(x[(i, j)]) for j in J] for i in I],\n",
    "    columns=[f\"Facility {j}\" for j in J],\n",
    "    index=p.index,\n",
    ")\n",
    "df[\"demand\"] = d_i\n",
    "df[\"satisfied\"] = sum(df[f\"Facility {j}\"] * c_j[j] for j in J)\n",
    "df[\"cost\"] = sum(df[f\"Facility {j}\"] * f_j[j] for j in J)\n",
    "df[\"comb\"] = df.apply(lambda x: tuple(x[: len(J)]), axis=1)\n",
    "\n",
    "display(df.comb.unique().size, df.comb.unique())\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set facility capacity\n",
    "\n",
    "We have m types of facilities with different capacities, the proposal is to use the data generated in the previous step to determine the capacity of each facility type in order to satisfy the demand.\n",
    "Machine Learning algorithms will be used to Classify the type of facility that will be needed for each municipality.\n",
    "- Decision Tree.\n",
    "- Linear Discriminant Analysis.\n",
    "- Logistic Regression.\n",
    "- Support Vector Machine.\n",
    "\n",
    "and deep learning to create a new model. The best model will be used to determine the capacity of each facility type.\n",
    "\n",
    "The objective is to predict 'comb' with the information of 'demand', 'lat', 'lon', and 'dp'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.00 s\n",
      "    Accuracy: 1.0\n",
      "    Confusion Matrix: \n",
      " [[  2   0   0   0   0]\n",
      " [  0   1   0   0   0]\n",
      " [  0   0   2   0   0]\n",
      " [  0   0   0 184   0]\n",
      " [  0   0   0   0   1]]\n",
      "    Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00       184\n",
      "          10       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       190\n",
      "   macro avg       1.00      1.00      1.00       190\n",
      "weighted avg       1.00      1.00      1.00       190\n",
      "\n",
      "Linear Discriminant Analysis: 0.00 s\n",
      "    Accuracy: 0.9842105263157894\n",
      "    Confusion Matrix: \n",
      " [[  2   0   0   0   0]\n",
      " [  0   1   0   0   0]\n",
      " [  0   0   2   0   0]\n",
      " [  3   0   0 181   0]\n",
      " [  0   0   0   0   1]]\n",
      "    Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      1.00      0.57         2\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         2\n",
      "           9       1.00      0.98      0.99       184\n",
      "          10       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.98       190\n",
      "   macro avg       0.88      1.00      0.91       190\n",
      "weighted avg       0.99      0.98      0.99       190\n",
      "\n",
      "Logistic Regression: 0.02 s\n",
      "    Accuracy: 0.968421052631579\n",
      "    Confusion Matrix: \n",
      " [[  0   0   0   2   0]\n",
      " [  1   0   0   0   0]\n",
      " [  2   0   0   0   0]\n",
      " [  0   0   0 184   0]\n",
      " [  0   1   0   0   0]]\n",
      "    Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           9       0.99      1.00      0.99       184\n",
      "          10       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       190\n",
      "   macro avg       0.60      0.20      0.20       190\n",
      "weighted avg       0.97      0.97      0.96       190\n",
      "\n",
      "Support Vector Machine: 0.01 s\n",
      "    Accuracy: 0.968421052631579\n",
      "    Confusion Matrix: \n",
      " [[  0   0   0   2   0]\n",
      " [  0   0   0   1   0]\n",
      " [  2   0   0   0   0]\n",
      " [  0   0   0 184   0]\n",
      " [  0   0   0   1   0]]\n",
      "    Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           9       0.98      1.00      0.99       184\n",
      "          10       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97       190\n",
      "   macro avg       0.80      0.20      0.20       190\n",
      "weighted avg       0.97      0.97      0.96       190\n",
      "\n",
      "Neural Network: 1.27 s\n",
      "    Accuracy: 0.9789473684210527\n",
      "    Confusion Matrix: \n",
      " [[  0   0   0   0   0   0]\n",
      " [  0   1   0   0   1   0]\n",
      " [  0   0   1   0   0   0]\n",
      " [  2   0   0   0   0   0]\n",
      " [  0   0   0   0 184   0]\n",
      " [  0   0   1   0   0   0]]\n",
      "    Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         0\n",
      "           1       1.00      0.50      0.67         2\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           9       0.99      1.00      1.00       184\n",
      "          10       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       190\n",
      "   macro avg       0.75      0.58      0.39       190\n",
      "weighted avg       0.99      0.98      0.98       190\n",
      "\n",
      "\n",
      "Best model: DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(df.copy(), population.copy(), left_index=True, right_index=True)\n",
    "# drop rows with nan in the 'comb' column\n",
    "data = data.dropna(subset=[\"comb\"])\n",
    "# train with a random sample of 80% of the data\n",
    "# The objective is to predict 'comb' with the information of 'demand', 'lat', 'lon', and 'dp'.\n",
    "# Convert 'comb' to string and encode it\n",
    "data[\"comb\"] = data[\"comb\"].apply(lambda x: str(x))\n",
    "data[\"comb\"] = LabelEncoder().fit_transform(data[\"comb\"])\n",
    "\n",
    "# Standardize the selected features\n",
    "data[[\"demand\", \"lat\", \"lon\", \"dp\"]] = StandardScaler().fit_transform(\n",
    "    data[[\"demand\", \"lat\", \"lon\", \"dp\"]]\n",
    ")\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data[[\"demand\", \"lat\", \"lon\", \"dp\"]], data[\"comb\"], test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "# Define and evaluate models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000, tol=1e-4),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "results = {}\n",
    "\n",
    "\n",
    "def evaluate_model(model_name, model):\n",
    "    global best_model, best_accuracy\n",
    "    start_time = time.time()\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": confusion_matrix(test_y, predictions),\n",
    "        \"classification_report\": classification_report(\n",
    "            test_y, predictions, zero_division=1\n",
    "        ),\n",
    "        \"time\": elapsed_time,\n",
    "    }\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    evaluate_model(model_name, model)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: {metrics['time']:.2f} s\")\n",
    "    print(f\"    Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"    Confusion Matrix: \\n {metrics['confusion_matrix']}\")\n",
    "    print(f\"    Classification Report: \\n {metrics['classification_report']}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Propose a k parameter for clustering using Linear Programming\n",
    "\n",
    "The proposal is to use the data generated in the previous step to determine the number of clusters that will be needed to satisfy the demand. The objective is to minimize the total cost of the facilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Inertia",
         "type": "scatter",
         "x": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          5821.033951132773,
          3593.571953480262,
          2766.0156795732787,
          1929.1758669972285,
          1569.7066600501946,
          1338.6244108121948,
          1217.6004494995923,
          1145.1972790884474,
          1013.7514445860922,
          955.9649662426225,
          863.4361662657232,
          790.7997728104897,
          676.8945667649474,
          642.4479684000637,
          589.7222341555305,
          574.0465486439248,
          556.5187639574809,
          533.4944729480364
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "name": "Silhouette Score",
         "type": "scatter",
         "x": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.3758170415524292,
          0.4505639821963598,
          0.46749345703456624,
          0.44682747543577744,
          0.4368903038722778,
          0.4201127232811126,
          0.40370874629293535,
          0.3931435220738836,
          0.3830963188471024,
          0.3727942138111521,
          0.3715178573102884,
          0.37472277938932547,
          0.40186075574603886,
          0.3760426720407342,
          0.3918423356826182,
          0.3621605437267394,
          0.35401385015220105,
          0.36173817193065205
         ],
         "yaxis": "y2"
        },
        {
         "mode": "lines+markers",
         "name": "Davies-Bouldin Score",
         "type": "scatter",
         "x": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "y": [
          0.9860028651447288,
          0.7638485669918672,
          0.7050099376782488,
          0.7345731663532081,
          0.7171013181782905,
          0.712364145985254,
          0.7597816609036663,
          0.7751863787228387,
          0.8005457612598862,
          0.8093926232279004,
          0.822948616330315,
          0.79992803031477,
          0.7672164900508316,
          0.8035659690375151,
          0.7951936707758386,
          0.8179408197804089,
          0.8493718999060246,
          0.8244650571989449
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Metric"
         }
        },
        "margin": {
         "r": 100,
         "t": 100
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Clustering Metrics"
        },
        "xaxis": {
         "title": {
          "text": "Number of Clusters"
         }
        },
        "yaxis": {
         "showgrid": false,
         "side": "left",
         "title": {
          "text": "Normalized Inertia"
         },
         "zeroline": false
        },
        "yaxis2": {
         "overlaying": "y",
         "showgrid": false,
         "side": "right",
         "title": {
          "standoff": 10,
          "text": "Normalized Score (0-1)"
         },
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example data (replace with your actual data)\n",
    "data = population.copy()\n",
    "data = data.loc[:, [\"lat\", \"lon\"]]\n",
    "\n",
    "# Initialize dictionaries to store metrics\n",
    "metrics = {\"inertia\": [], \"silhouette\": [], \"davies_bouldin\": []}\n",
    "\n",
    "# Range for the number of clusters\n",
    "cluster_range = range(2, 20)\n",
    "\n",
    "# Calculate metrics for each number of clusters\n",
    "for i in cluster_range:\n",
    "    model = KMeans(n_clusters=i, random_state=0)\n",
    "    model.fit(data[[\"lat\", \"lon\"]])\n",
    "    metrics[\"inertia\"].append(model.inertia_)\n",
    "    metrics[\"silhouette\"].append(silhouette_score(data[[\"lat\", \"lon\"]], model.labels_))\n",
    "    metrics[\"davies_bouldin\"].append(\n",
    "        davies_bouldin_score(data[[\"lat\", \"lon\"]], model.labels_)\n",
    "    )\n",
    "\n",
    "# Create interactive plots using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Inertia Plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(cluster_range),\n",
    "        y=metrics[\"inertia\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Inertia\",\n",
    "        yaxis=\"y\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Silhouette Plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(cluster_range),\n",
    "        y=metrics[\"silhouette\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Silhouette Score\",\n",
    "        yaxis=\"y2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Davies-Bouldin Plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(cluster_range),\n",
    "        y=metrics[\"davies_bouldin\"],\n",
    "        mode=\"lines+markers\",\n",
    "        name=\"Davies-Bouldin Score\",\n",
    "        yaxis=\"y2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Clustering Metrics\",\n",
    "    xaxis_title=\"Number of Clusters\",\n",
    "    yaxis_title=\"Normalized Inertia\",\n",
    "    legend_title=\"Metric\",\n",
    "    template=\"plotly_white\",\n",
    "    yaxis=dict(side=\"left\", showgrid=False, zeroline=False, title=\"Normalized Inertia\"),\n",
    "    yaxis2=dict(\n",
    "        side=\"right\",\n",
    "        overlaying=\"y\",\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        title=\"Normalized Score (0-1)\",\n",
    "        title_standoff=10,  # Adjust the distance between the axis title and axis tick labels\n",
    "    ),\n",
    "    margin=dict(r=100, t=100),  # Adjust the right and top margins\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Cluster centers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116]\n",
      "Assignments: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45, 46: 46, 47: 47, 48: 48, 49: 49, 50: 50, 51: 51, 52: 52, 53: 53, 54: 54, 55: 55, 56: 56, 57: 57, 58: 58, 59: 59, 60: 60, 61: 61, 62: 62, 63: 63, 64: 64, 65: 65, 66: 66, 67: 67, 68: 68, 69: 69, 70: 70, 71: 71, 72: 72, 73: 73, 74: 74, 75: 75, 76: 76, 77: 77, 78: 78, 79: 79, 80: 80, 81: 81, 82: 82, 83: 83, 84: 84, 85: 85, 86: 86, 87: 87, 88: 88, 89: 89, 90: 90, 91: 91, 92: 92, 93: 93, 94: 94, 95: 95, 96: 96, 97: 97, 98: 98, 99: 99, 100: 100, 101: 101, 102: 102, 103: 103, 104: 104, 105: 105, 106: 106, 107: 107, 108: 108, 109: 109, 110: 110, 111: 111, 112: 112, 113: 113, 114: 114, 115: 115, 116: 116, 117: 117, 118: 118, 119: 119, 120: 120, 121: 121, 122: 122, 123: 123, 124: 124, 125: 125, 126: 126, 127: 127, 128: 128, 129: 129, 130: 130, 131: 131, 132: 132, 133: 133, 134: 134, 135: 135, 136: 136, 137: 137, 138: 138, 139: 139, 140: 140, 141: 141, 142: 142, 143: 143, 144: 144, 145: 145, 146: 146, 147: 147, 148: 148, 149: 149, 150: 150, 151: 151, 152: 152, 153: 153, 154: 154, 155: 155, 156: 156, 157: 157, 158: 158, 159: 159, 160: 160, 161: 161, 162: 162, 163: 163, 164: 164, 165: 165, 166: 166, 167: 167, 168: 168, 169: 169, 170: 170, 171: 171, 172: 172, 173: 173, 174: 174, 175: 175, 176: 176, 177: 177, 178: 178, 179: 179, 180: 180, 181: 181, 182: 182, 183: 183, 184: 184, 185: 185, 186: 186, 187: 187, 188: 188, 189: 189, 190: 190, 191: 191, 192: 192, 193: 193, 194: 194, 195: 195, 196: 196, 197: 197, 198: 198, 199: 199, 200: 200, 201: 201, 202: 202, 203: 203, 204: 204, 205: 205, 206: 206, 207: 207, 208: 208, 209: 209, 210: 210, 211: 211, 212: 212, 213: 213, 214: 214, 215: 215, 216: 216, 217: 217, 218: 218, 219: 219, 220: 220, 221: 221, 222: 222, 223: 223, 224: 224, 225: 225, 226: 226, 227: 227, 228: 228, 229: 229, 230: 230, 231: 231, 232: 232, 233: 233, 234: 234, 235: 235, 236: 236, 237: 237, 238: 238, 239: 239, 240: 240, 241: 241, 242: 242, 243: 243, 244: 244, 245: 245, 246: 246, 247: 247, 248: 248, 249: 249, 250: 250, 251: 251, 252: 252, 253: 253, 254: 254, 255: 255, 256: 256, 257: 257, 258: 258, 259: 259, 260: 260, 261: 261, 262: 262, 263: 263, 264: 264, 265: 265, 266: 266, 267: 267, 268: 268, 269: 269, 270: 270, 271: 271, 272: 272, 273: 273, 274: 274, 275: 275, 276: 276, 277: 277, 278: 278, 279: 279, 280: 280, 281: 281, 282: 282, 283: 283, 284: 284, 285: 285, 286: 286, 287: 287, 288: 288, 289: 289, 290: 290, 291: 291, 292: 292, 293: 293, 294: 294, 295: 295, 296: 296, 297: 297, 298: 298, 299: 299, 300: 300, 301: 301, 302: 302, 303: 303, 304: 304, 305: 305, 306: 306, 307: 307, 308: 308, 309: 309, 310: 310, 311: 311, 312: 312, 313: 313, 314: 314, 315: 315, 316: 316, 317: 317, 318: 318, 319: 319, 320: 320, 321: 321, 322: 322, 323: 323, 324: 324, 325: 325, 326: 326, 327: 327, 328: 328, 329: 329, 330: 330, 331: 331, 332: 332, 333: 333, 334: 334, 335: 335, 336: 336, 337: 337, 338: 338, 339: 339, 340: 340, 341: 341, 342: 342, 343: 343, 344: 344, 345: 345, 346: 346, 347: 347, 348: 348, 349: 349, 350: 350, 351: 351, 352: 352, 353: 353, 354: 354, 355: 355, 356: 356, 357: 357, 358: 358, 359: 359, 360: 360, 361: 361, 362: 362, 363: 363, 364: 364, 365: 365, 366: 366, 367: 367, 368: 368, 369: 369, 370: 370, 371: 371, 372: 372, 373: 373, 374: 374, 375: 375, 376: 376, 377: 377, 378: 378, 379: 379, 380: 380, 381: 381, 382: 382, 383: 383, 384: 384, 385: 385, 386: 386, 387: 387, 388: 388, 389: 389, 390: 390, 391: 391, 392: 392, 393: 393, 394: 394, 395: 395, 396: 396, 397: 397, 398: 398, 399: 399, 400: 400, 401: 401, 402: 402, 403: 403, 404: 404, 405: 405, 406: 406, 407: 407, 408: 408, 409: 409, 410: 410, 411: 411, 412: 412, 413: 413, 414: 414, 415: 415, 416: 416, 417: 417, 418: 418, 419: 419, 420: 420, 421: 421, 422: 422, 423: 423, 424: 424, 425: 425, 426: 426, 427: 427, 428: 428, 429: 429, 430: 430, 431: 431, 432: 432, 433: 433, 434: 434, 435: 435, 436: 436, 437: 437, 438: 438, 439: 439, 440: 440, 441: 441, 442: 442, 443: 443, 444: 444, 445: 445, 446: 446, 447: 447, 448: 448, 449: 449, 450: 450, 451: 451, 452: 452, 453: 453, 454: 454, 455: 455, 456: 456, 457: 457, 458: 458, 459: 459, 460: 460, 461: 461, 462: 462, 463: 463, 464: 464, 465: 465, 466: 466, 467: 467, 468: 468, 469: 469, 470: 470, 471: 471, 472: 472, 473: 473, 474: 474, 475: 475, 476: 476, 477: 477, 478: 478, 479: 479, 480: 480, 481: 481, 482: 482, 483: 483, 484: 484, 485: 485, 486: 486, 487: 487, 488: 488, 489: 489, 490: 490, 491: 491, 492: 492, 493: 493, 494: 494, 495: 495, 496: 496, 497: 497, 498: 498, 499: 508, 500: 500, 501: 512, 502: 502, 503: 503, 504: 504, 505: 505, 506: 506, 507: 507, 508: 499, 509: 502, 510: 510, 511: 511, 512: 512, 513: 513, 514: 514, 515: 955, 516: 516, 517: 517, 518: 518, 519: 519, 520: 520, 521: 521, 522: 522, 523: 523, 524: 524, 525: 525, 526: 526, 527: 527, 528: 528, 529: 529, 530: 530, 531: 531, 532: 532, 533: 533, 534: 534, 535: 535, 536: 536, 537: 537, 538: 538, 539: 539, 540: 540, 541: 541, 542: 542, 543: 543, 544: 544, 545: 545, 546: 546, 547: 547, 548: 548, 549: 549, 550: 550, 551: 551, 552: 552, 553: 553, 554: 554, 555: 555, 556: 556, 557: 557, 558: 558, 559: 559, 560: 560, 561: 561, 562: 562, 563: 563, 564: 564, 565: 565, 566: 566, 567: 567, 568: 568, 569: 569, 570: 570, 571: 571, 572: 572, 573: 573, 574: 574, 575: 575, 576: 576, 577: 577, 578: 578, 579: 579, 580: 580, 581: 581, 582: 582, 583: 583, 584: 584, 585: 585, 586: 586, 587: 587, 588: 588, 589: 589, 590: 590, 591: 591, 592: 592, 593: 593, 594: 594, 595: 595, 596: 596, 597: 597, 598: 598, 599: 599, 600: 600, 601: 601, 602: 602, 603: 603, 604: 604, 605: 605, 606: 606, 607: 607, 608: 608, 609: 609, 610: 610, 611: 611, 612: 612, 613: 613, 614: 614, 615: 615, 616: 616, 617: 617, 618: 618, 619: 619, 620: 620, 621: 621, 622: 622, 623: 623, 624: 624, 625: 625, 626: 626, 627: 627, 628: 628, 629: 629, 630: 630, 631: 631, 632: 632, 633: 633, 634: 634, 635: 635, 636: 636, 637: 637, 638: 638, 639: 639, 640: 640, 641: 641, 642: 642, 643: 643, 644: 644, 645: 645, 646: 646, 647: 647, 648: 648, 649: 649, 650: 650, 651: 647, 652: 652, 653: 653, 654: 654, 655: 655, 656: 656, 657: 657, 658: 658, 659: 659, 660: 660, 661: 661, 662: 662, 663: 663, 664: 664, 665: 665, 666: 666, 667: 667, 668: 668, 669: 669, 670: 670, 671: 671, 672: 672, 673: 673, 674: 674, 675: 675, 676: 676, 677: 677, 678: 678, 679: 679, 680: 680, 681: 681, 682: 682, 683: 683, 684: 684, 685: 685, 686: 686, 687: 687, 688: 688, 689: 689, 690: 690, 691: 691, 692: 692, 693: 693, 694: 694, 695: 695, 696: 696, 697: 697, 698: 698, 699: 699, 700: 700, 701: 701, 702: 702, 703: 703, 704: 704, 705: 705, 706: 706, 707: 707, 708: 708, 709: 709, 710: 710, 711: 711, 712: 712, 713: 713, 714: 714, 715: 715, 716: 716, 717: 717, 718: 718, 719: 719, 720: 720, 721: 721, 722: 722, 723: 723, 724: 724, 725: 725, 726: 726, 727: 727, 728: 728, 729: 729, 730: 730, 731: 731, 732: 732, 733: 733, 734: 734, 735: 735, 736: 736, 737: 737, 738: 738, 739: 739, 740: 740, 741: 741, 742: 742, 743: 743, 744: 744, 745: 745, 746: 746, 747: 747, 748: 748, 749: 749, 750: 750, 751: 751, 752: 752, 753: 753, 754: 754, 755: 755, 756: 756, 757: 757, 758: 758, 759: 759, 760: 760, 761: 761, 762: 762, 763: 763, 764: 764, 765: 765, 766: 766, 767: 767, 768: 768, 769: 769, 770: 770, 771: 771, 772: 772, 773: 773, 774: 774, 775: 775, 776: 776, 777: 777, 778: 778, 779: 779, 780: 780, 781: 781, 782: 782, 783: 783, 784: 784, 785: 785, 786: 786, 787: 787, 788: 788, 789: 789, 790: 790, 791: 791, 792: 792, 793: 793, 794: 794, 795: 795, 796: 796, 797: 797, 798: 798, 799: 799, 800: 800, 801: 801, 802: 802, 803: 803, 804: 804, 805: 805, 806: 806, 807: 807, 808: 808, 809: 809, 810: 810, 811: 811, 812: 812, 813: 813, 814: 814, 815: 815, 816: 816, 817: 817, 818: 818, 819: 819, 820: 820, 821: 821, 822: 822, 823: 823, 824: 824, 825: 825, 826: 826, 827: 827, 828: 828, 829: 829, 830: 830, 831: 831, 832: 832, 833: 833, 834: 834, 835: 835, 836: 836, 837: 837, 838: 838, 839: 839, 840: 840, 841: 841, 842: 842, 843: 843, 844: 844, 845: 845, 846: 846, 847: 847, 848: 848, 849: 849, 850: 850, 851: 851, 852: 852, 853: 853, 854: 854, 855: 855, 856: 856, 857: 902, 858: 858, 859: 859, 860: 860, 861: 861, 862: 873, 863: 863, 864: 865, 865: 864, 866: 873, 867: 871, 868: 868, 869: 869, 870: 871, 871: 867, 872: 857, 873: 873, 874: 874, 875: 875, 876: 876, 877: 877, 878: 878, 879: 879, 880: 880, 881: 881, 882: 882, 883: 883, 884: 884, 885: 885, 886: 886, 887: 887, 888: 888, 889: 889, 890: 890, 891: 891, 892: 892, 893: 893, 894: 894, 895: 895, 896: 896, 897: 897, 898: 898, 899: 899, 900: 900, 901: 901, 902: 902, 903: 903, 904: 904, 905: 905, 906: 906, 907: 907, 908: 908, 909: 909, 910: 910, 911: 911, 912: 912, 913: 913, 914: 914, 915: 915, 916: 916, 917: 917, 918: 918, 919: 919, 920: 884, 921: 921, 922: 922, 923: 923, 924: 924, 925: 925, 926: 926, 927: 927, 928: 928, 929: 929, 930: 930, 931: 931, 932: 932, 933: 933, 934: 934, 935: 935, 936: 936, 937: 937, 938: 938, 939: 939, 940: 940, 941: 941, 942: 942, 943: 943, 944: 944, 945: 945, 946: 946, 947: 947, 948: 948, 949: 949, 950: 950, 951: 951, 952: 952, 953: 953, 954: 954, 955: 955, 956: 956, 957: 957, 958: 958, 959: 959, 960: 960, 961: 961, 962: 962, 963: 963, 964: 964, 965: 965, 966: 966, 967: 967, 968: 968, 969: 969, 970: 970, 971: 971, 972: 972, 973: 973, 974: 974, 975: 975, 976: 976, 977: 977, 978: 978, 979: 979, 980: 980, 981: 981, 982: 982, 983: 983, 984: 984, 985: 985, 986: 986, 987: 987, 988: 988, 989: 989, 990: 990, 991: 991, 992: 992, 993: 993, 994: 994, 995: 995, 996: 996, 997: 997, 998: 998, 999: 999, 1000: 1000, 1001: 1001, 1002: 1002, 1003: 1003, 1004: 1004, 1005: 1005, 1006: 1006, 1007: 1007, 1008: 1008, 1009: 1009, 1010: 1010, 1011: 1011, 1012: 1012, 1013: 1013, 1014: 1014, 1015: 1015, 1016: 1016, 1017: 1017, 1018: 1018, 1019: 1019, 1020: 1020, 1021: 1021, 1022: 1022, 1023: 1023, 1024: 1024, 1025: 1025, 1026: 1026, 1027: 1027, 1028: 1028, 1029: 1029, 1030: 1030, 1031: 1031, 1032: 1032, 1033: 1033, 1034: 1034, 1035: 1035, 1036: 1036, 1037: 1037, 1038: 1038, 1039: 1039, 1040: 1040, 1041: 1041, 1042: 1042, 1043: 1043, 1044: 1044, 1045: 1045, 1046: 1046, 1047: 1047, 1048: 1048, 1049: 1049, 1050: 1050, 1051: 1051, 1052: 1052, 1053: 1053, 1054: 1054, 1055: 1055, 1056: 1056, 1057: 1057, 1058: 1058, 1059: 1059, 1060: 1060, 1061: 1061, 1062: 1062, 1063: 1063, 1064: 1064, 1065: 1065, 1066: 1066, 1067: 1067, 1068: 1068, 1069: 1069, 1070: 1070, 1071: 1071, 1072: 1072, 1073: 1073, 1074: 1074, 1075: 1075, 1076: 1076, 1077: 1077, 1078: 1078, 1079: 1079, 1080: 1080, 1081: 1081, 1082: 1082, 1083: 1083, 1084: 1084, 1085: 1085, 1086: 1086, 1087: 1087, 1088: 1088, 1089: 1089, 1090: 1090, 1091: 1091, 1092: 1092, 1093: 1093, 1094: 1094, 1095: 1095, 1096: 1096, 1097: 1097, 1098: 1098, 1099: 1099, 1100: 1100, 1101: 1101, 1102: 1102, 1103: 1103, 1104: 1104, 1105: 1105, 1106: 1106, 1107: 1107, 1108: 1108, 1109: 1109, 1110: 1110, 1111: 1111, 1112: 1112, 1113: 1113, 1114: 1114, 1115: 1115, 1116: 1116}\n",
      "Objective function: 0.0\n",
      "Number of open facilities: 1117\n"
     ]
    }
   ],
   "source": [
    "data = population.copy()\n",
    "distance = distance.copy()\n",
    "\n",
    "cost_matrix = distance.values\n",
    "\n",
    "# Number of points\n",
    "n_points = data.shape[0]\n",
    "\n",
    "# Define the problem\n",
    "prob = pulp.LpProblem(\"UFLP\", pulp.LpMinimize)\n",
    "\n",
    "# Decision variables\n",
    "x = pulp.LpVariable.dicts(\n",
    "    \"assign\", (range(n_points), range(n_points)), cat=pulp.LpBinary\n",
    ")\n",
    "y = pulp.LpVariable.dicts(\"open\", range(n_points), cat=pulp.LpBinary)\n",
    "\n",
    "# Objective function\n",
    "prob += pulp.lpSum(\n",
    "    cost_matrix[i][j] * x[i][j] for i in range(n_points) for j in range(n_points)\n",
    ")\n",
    "\n",
    "# Constraints\n",
    "for i in range(n_points):\n",
    "    prob += (\n",
    "        pulp.lpSum(x[i][j] for j in range(n_points)) == 1\n",
    "    )  # Each client is assigned to one facility\n",
    "\n",
    "for j in range(n_points):\n",
    "    for i in range(n_points):\n",
    "        prob += x[i][j] <= y[j]  # Clients can only be assigned to open facilities\n",
    "\n",
    "# Solve the problem\n",
    "prob.solve()\n",
    "\n",
    "# Output results\n",
    "print(f\"Status: {pulp.LpStatus[prob.status]}\")\n",
    "\n",
    "cluster_centers = [j for j in range(n_points) if y[j].varValue > 0.5]\n",
    "assignments = {\n",
    "    i: j for i in range(n_points) for j in range(n_points) if x[i][j].varValue > 0.5\n",
    "}\n",
    "\n",
    "print(f\"Cluster centers: {cluster_centers}\")\n",
    "print(f\"Assignments: {assignments}\")\n",
    "print(f\"Objective function: {pulp.value(prob.objective)}\")\n",
    "print(f\"Number of open facilities: {len(cluster_centers)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
