{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capacitated Facility Location Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"16 BCFLP\"\n",
    "sample_fraq = 0.1\n",
    "randomSeed = 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance\n",
    "\n",
    "# Plotting modules\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Linear programming modules\n",
    "import pulp\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# == Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# == Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# == Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "# == Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# == Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      "    food_per_person_per_day: 0.00087617 \n",
      "    transport_cost_per_ton_per_km: 3364.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data information: \n",
      "    population: (112, 71) \n",
      "    distance: (112, 112) \n",
      "    warehouses: \n",
      "    Type  capacity_ton        cost\n",
      "0     1          1074  3111202.75\n",
      "1     2          2418  4804980.75 \n",
      "\n",
      "population memory usage: 0.07 MB\n",
      "distance memory usage: 0.10 MB\n",
      "warehouses memory usage: 0.00 MB\n",
      "Elapsed time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "# import the data and parameters and check the data\n",
    "\n",
    "data_path = \"data/\"\n",
    "start_time = time.time()\n",
    "# ====Parameters==== #\n",
    "parameters = pd.read_csv(os.path.join(data_path, \"parametros.csv\"))\n",
    "# 1. food_per_person_per_day in tons per day\n",
    "food_per_person_per_day = float(\n",
    "    parameters.loc[parameters[\"parametro\"] == \"comida_por_persona_en_toneladas\"].values[\n",
    "        0\n",
    "    ][1]\n",
    ")\n",
    "# 2. transport_cost_per_ton_per_km in COP per ton per km\n",
    "transport_cost_per_ton_per_km = float(\n",
    "    parameters.loc[\n",
    "        parameters[\"parametro\"] == \"costo_de_transporte_por_tonelada_por_kilomentro\"\n",
    "    ].values[0][1]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"parameters: \\n    food_per_person_per_day: {food_per_person_per_day} \\n    transport_cost_per_ton_per_km: {transport_cost_per_ton_per_km}\\n\"\n",
    ")\n",
    "# ====Parameters==== #\n",
    "\n",
    "# ====importData==== #\n",
    "# 1. population, from data/municipios_procesado.csv\n",
    "population = pd.read_csv(\n",
    "    os.path.join(data_path, \"municipios_procesado.csv\"), index_col=3\n",
    ")\n",
    "# 2. distance, from data/distance_matrix_final.csv\n",
    "distance = pd.read_csv(\n",
    "    os.path.join(data_path, \"distance_matrix_final.csv\"), index_col=0\n",
    ")\n",
    "# 3. warehouses, from data/almacenes.csv\n",
    "warehouses = pd.read_csv(os.path.join(data_path, \"almacenes.csv\"))\n",
    "# ====importData==== #\n",
    "\n",
    "# ====DataProcessing===== #\n",
    "# fill the nan values in population with the minimum '2024' from the departamento of Chocó for the columns 22:\n",
    "population.loc[population.isna().any(axis=1), population.columns[18:]] = (\n",
    "    population[\n",
    "        population[\"2024\"]\n",
    "        == population.loc[population[\"departamento\"] == \"Chocó\"][\"2024\"].min()\n",
    "    ]\n",
    "    .iloc[0, 18:]\n",
    "    .values\n",
    ")\n",
    "# drop the municipalities with nan values in the first column of the distance matrix\n",
    "distance = distance.dropna(subset=[distance.columns[0]], axis=0)\n",
    "distance = distance.dropna(subset=[distance.index[0]], axis=1)\n",
    "# turn the columns of distance into integers\n",
    "distance.columns = distance.columns.astype(int)\n",
    "# Take a sample of the data\n",
    "distance = distance.sample(frac=sample_fraq, random_state=randomSeed)\n",
    "distance = distance.loc[\n",
    "    :, distance.index\n",
    "]  # make the distance matrix symmetric # type: ignore\n",
    "# if there is a 0 value that is not in the diagonal, replace it with the mean of the column\n",
    "for i in distance.index:\n",
    "    for j in distance.columns:\n",
    "        if distance.loc[i, j] == 0 and i != j:\n",
    "            distance.loc[i, j] = np.nan\n",
    "# Drop the nan values\n",
    "distance = distance.dropna()\n",
    "# make the distance matrix symmetric\n",
    "distance = distance.loc[:, distance.index]\n",
    "# turn distance to km\n",
    "distance = distance / 1000\n",
    "# select only the rows in population dpmp that the index is in distance\n",
    "population = population.loc[distance.index]\n",
    "# Check if every value of distance is larger than the linear distance for every pair of municipalities in population lat and lon are in the population dataframe\n",
    "for i in distance.index:\n",
    "    for j in distance.columns:\n",
    "        if i != j:\n",
    "            # get the linear distance\n",
    "            linear_distance = geopy.distance.distance(\n",
    "                (population.loc[i, \"lat\"], population.loc[i, \"lon\"]),\n",
    "                (population.loc[j, \"lat\"], population.loc[j, \"lon\"]),\n",
    "            ).km\n",
    "            # check if the linear distance is larger than the distance in the distance matrix\n",
    "            if linear_distance > distance.loc[i, j]:\n",
    "                distance.loc[i, j] = linear_distance\n",
    "# Check if there are any nan values in distance\n",
    "if distance.isna().any().any():\n",
    "    print(\"There are nan values in the distance matrix\")\n",
    "print(\n",
    "    f\"data information: \\n    population: {population.shape} \\n    distance: {distance.shape} \\n    warehouses: \\n {warehouses} \\n\"\n",
    ")\n",
    "# ====DataProcessing===== #\n",
    "\n",
    "# ====DataInformation==== #\n",
    "# Memory usage of the data\n",
    "print(f\"population memory usage: {population.memory_usage().sum()/1024**2:.2f} MB\")  # type: ignore\n",
    "print(f\"distance memory usage: {distance.memory_usage().sum()/1024**2:.2f} MB\")  # type: ignore\n",
    "print(f\"warehouses memory usage: {warehouses.memory_usage().sum()/1024**2:.2f} MB\")  # type: ignore\n",
    "# ====DataInformation==== #\n",
    "\n",
    "# ====DataChecking==== #\n",
    "# Test to the data if needed\n",
    "# ====DataChecking==== #\n",
    "print(f\"Elapsed time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Demand Forecast\n",
    "\n",
    "we are using the data from the population dataset that has the colombian census information since 1985 to 2035, the current year is 2024 and the last census was performed in 2018, the data was taken on december 2023 from the DANE web page.\n",
    "\n",
    "First we need to check the current forecast, then use 4 ML algorithms and Deep Learning to create a new model. The Machine Learning algorithms are:\n",
    "- Multiple Linear Regression.\n",
    "- Regression Tree.\n",
    "- Support Vector Machine.\n",
    "- Random Forest Regression.\n",
    "\n",
    "Then, we need the Mean Absolute Error (MAE) to compare the models. The best model will be used to forecast the demand for the next 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45819/2739782838.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  general_results = pd.concat(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Municipio</th>\n",
       "      <th colspan=\"4\" halign=\"left\">R2</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MSE</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MAE</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regression</td>\n",
       "      <td>105</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regression Tree</td>\n",
       "      <td>102</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>102</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiple Linear Regression</td>\n",
       "      <td>75</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.028</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Network for population regression</td>\n",
       "      <td>26</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.191</td>\n",
       "      <td>3.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Modelo Municipio     R2                \\\n",
       "                                                count    min   mean    std   \n",
       "2                  Random Forest Regression       105  0.932  0.981  0.014   \n",
       "3                           Regression Tree       102  0.925  0.971  0.015   \n",
       "4                    Support Vector Machine       102  0.931  0.986  0.013   \n",
       "0                Multiple Linear Regression        75  0.901  0.969  0.028   \n",
       "1  Neural Network for population regression        26  0.935  0.988  0.016   \n",
       "\n",
       "            MSE                         MAE                        Time  \\\n",
       "     max    min   mean    std    max    min   mean    std    max    min   \n",
       "2  0.998  0.001  0.012  0.008  0.038  0.024  0.079  0.026  0.155  0.011   \n",
       "3  0.993  0.008  0.018  0.009  0.055  0.076  0.114  0.021  0.192  0.002   \n",
       "4  0.998  0.001  0.009  0.009  0.050  0.025  0.070  0.028  0.151  0.002   \n",
       "0  1.000  0.000  0.020  0.018  0.074  0.010  0.104  0.060  0.253  0.002   \n",
       "1  0.999  0.000  0.007  0.009  0.038  0.011  0.057  0.036  0.154  0.108   \n",
       "\n",
       "                               \n",
       "    mean    std    max    sum  \n",
       "2  0.016  0.005  0.041  1.698  \n",
       "3  0.003  0.001  0.005  0.267  \n",
       "4  0.003  0.001  0.013  0.267  \n",
       "0  0.003  0.002  0.013  0.195  \n",
       "1  0.150  0.024  0.191  3.900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ## 1. Demand Forecast\n",
    "\n",
    "# 1. Demand Forecast\n",
    "\n",
    "data = population.copy().iloc[:, 20:59]\n",
    "data = data.transpose()\n",
    "# replace 0 values with nan\n",
    "data = data.replace(0, np.nan)\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Multiple Linear Regression\": LinearRegression(),\n",
    "    \"Regression Tree\": DecisionTreeRegressor(\n",
    "        max_depth=100, min_samples_split=2, min_samples_leaf=1, random_state=randomSeed\n",
    "    ),\n",
    "    \"Support Vector Machine\": SVR(C=1.0, kernel=\"rbf\", gamma=\"scale\"),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(\n",
    "        n_estimators=10,\n",
    "        max_depth=5,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=randomSeed,\n",
    "    ),\n",
    "    \"Neural Network for population regression\": MLPRegressor(\n",
    "        hidden_layer_sizes=(10, 10, 10, 10, 10),\n",
    "        activation=\"logistic\",\n",
    "        solver=\"adam\",\n",
    "        alpha=0.01,\n",
    "        batch_size=\"auto\",\n",
    "        learning_rate=\"adaptive\",\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        shuffle=True,\n",
    "        random_state=randomSeed,\n",
    "    ),\n",
    "}\n",
    "\n",
    "general_results = pd.DataFrame(\n",
    "    columns=[\"Municipio\", \"Modelo\", \"R2\", \"MSE\", \"MAE\", \"Time\"]\n",
    ")\n",
    "for municipio in data.columns:\n",
    "    # print(f\"Forecasting demand for {municipio}\")\n",
    "    dataset = data.loc[:, municipio].dropna()\n",
    "    X = np.array(range(len(dataset))).reshape(-1, 1)\n",
    "    y = dataset.values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=randomSeed\n",
    "    )\n",
    "    for name, model in models.items():\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        general_results = pd.concat(\n",
    "            [\n",
    "                general_results,\n",
    "                pd.DataFrame(\n",
    "                    [[municipio, name, r2, mse, mae, time.time() - start_time]],\n",
    "                    columns=[\"Municipio\", \"Modelo\", \"R2\", \"MSE\", \"MAE\", \"Time\"],\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        # print(\n",
    "        #     f\"Model: {name} \\n    R2: {r2} \\n    MSE: {mse} \\n    MAE: {mae} \\n    Time: {time.time() - start_time:.2f} s\"\n",
    "        # )\n",
    "general_results = general_results[general_results[\"R2\"] > 0.9]\n",
    "# Group the results by model being count for the number of municipalities and the min, mean, std, and max for the R2, MSE, MAE, and Time\n",
    "dataframe_de_resultados = (\n",
    "    general_results.groupby(\"Modelo\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"Municipio\": \"count\",\n",
    "            \"R2\": [\"min\", \"mean\", \"std\", \"max\"],\n",
    "            \"MSE\": [\"min\", \"mean\", \"std\", \"max\"],\n",
    "            \"MAE\": [\"min\", \"mean\", \"std\", \"max\"],\n",
    "            \"Time\": [\"min\", \"mean\", \"std\", \"max\", \"sum\"],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ").sort_values((\"Municipio\", \"count\"), ascending=False)\n",
    "dataframe_de_resultados = dataframe_de_resultados.round(3)\n",
    "\n",
    "display(dataframe_de_resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
