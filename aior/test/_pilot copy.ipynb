{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncapacitated Facility Location Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "from lp.uflp import UFLP\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      "    food_per_person_per_day: 0.00087617 \n",
      "    transport_cost_per_ton_per_km: 3364.0\n",
      "\n",
      "data information: \n",
      "    population: (1117, 71) \n",
      "    distance: (1117, 1117) \n",
      "    warehouses: \n",
      "    Type  capacity_ton        cost\n",
      "0     1          1074   731159925\n",
      "1     2          2418  1129212606\n",
      "2     3          9672  4516850424 \n",
      "\n",
      "population memory usage: 0.61 MB\n",
      "distance memory usage: 9.56 MB\n",
      "warehouses memory usage: 0.00 MB\n",
      "Elapsed time: 0.29 s\n"
     ]
    }
   ],
   "source": [
    "# import the data and parameters and check the data\n",
    "\n",
    "data_path = 'data/'\n",
    "start_time = time.time()\n",
    "# ====Parameters==== #\n",
    "parameters = pd.read_csv(os.path.join(data_path, 'parametros.csv'))\n",
    "# 1. food_per_person_per_day in tons per day\n",
    "food_per_person_per_day = float(parameters.loc[\n",
    "    parameters['parametro'] == 'comida_por_persona_en_toneladas'].values[0][1])\n",
    "# 2. transport_cost_per_ton_per_km in COP per ton per km\n",
    "transport_cost_per_ton_per_km = float(\n",
    "    parameters.loc[parameters['parametro'] == 'costo_de_transporte_por_tonelada_por_kilomentro'].values[0][1])\n",
    "\n",
    "print(f'parameters: \\n    food_per_person_per_day: {food_per_person_per_day} \\n    transport_cost_per_ton_per_km: {transport_cost_per_ton_per_km}\\n')\n",
    "# ====Parameters==== #\n",
    "\n",
    "# ====importData==== #\n",
    "# 1. population, from data/municipios_procesado.csv\n",
    "population = pd.read_csv(os.path.join(data_path, 'municipios_procesado.csv'), index_col=3)\n",
    "# 2. distance, from data/distance_matrix_final.csv\n",
    "distance = pd.read_csv(os.path.join(data_path, 'distance_matrix_final.csv'), index_col=0)\n",
    "# 3. warehouses, from data/almacenes.csv\n",
    "warehouses = pd.read_csv(os.path.join(data_path, 'almacenes.csv'))\n",
    "# ====importData==== #\n",
    "\n",
    "# ====DataProcessing===== #\n",
    "# fill the nan values in population with the minimum '2024' from the departamento of Chocó for the columns 22:\n",
    "population.loc[population.isna().any(axis=1), population.columns[18:]] = population[population['2024'] == population.loc[population['departamento'] == 'Chocó']['2024'].min()].iloc[0, 18:].values\n",
    "# drop the municipalities with nan values in the first column of the distance matrix\n",
    "distance = distance.dropna(subset=[distance.columns[0]], axis=0)\n",
    "distance = distance.dropna(subset=[distance.index[0]], axis=1)\n",
    "# select only the rows in population dpmp that the index is in distance\n",
    "population = population.loc[distance.index]\n",
    "# turn the columns of distance into integers\n",
    "distance.columns = distance.columns.astype(int)\n",
    "print(f'data information: \\n    population: {population.shape} \\n    distance: {distance.shape} \\n    warehouses: \\n {warehouses} \\n')\n",
    "# ====DataProcessing===== #\n",
    "\n",
    "# ====DataInformation==== #\n",
    "# Memory usage of the data\n",
    "print(f'population memory usage: {population.memory_usage().sum()/1024**2:.2f} MB')\n",
    "print(f'distance memory usage: {distance.memory_usage().sum()/1024**2:.2f} MB')\n",
    "print(f'warehouses memory usage: {warehouses.memory_usage().sum()/1024**2:.2f} MB')\n",
    "# ====DataInformation==== #\n",
    "\n",
    "# ====DataChecking==== #\n",
    "# Test to the data if needed\n",
    "# ====DataChecking==== #\n",
    "print(f'Elapsed time: {time.time() - start_time:.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Demand Forecast\n",
    "\n",
    "we are using the data from the population dataset that has the colombian census information since 1985 to 2035, the current year is 2024 and the last census was performed in 2018, the data was taken on december 2023 from the DANE web page.\n",
    "\n",
    "First we need to check the current forecast, then use 4 ML algorithms and Deep Learning to create a new model. The Machine Learning algorithms are:\n",
    "- Multiple Linear Regression.\n",
    "- Regression Tree.\n",
    "- Support Vector Machine.\n",
    "- Random Forest Regression.\n",
    "\n",
    "Then, we need the Mean Absolute Error (MAE) to compare the models. The best model will be used to forecast the demand for the next 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1. Multiple Linear Regression: 2.31 s\n",
      "    Mean Absolute Error: 1983.0903511087888\n",
      "    Mean Squared Error: 271714255.3285868\n",
      "    R2 Score: 0.6550556575024784\n",
      "1.2. Regression Tree: 1.91 s\n",
      "    Mean Absolute Error: 506.4348254252462\n",
      "    Mean Squared Error: 12224571.61817368\n",
      "    R2 Score: 0.9839632368722134\n",
      "1.3. Support Vector Machine: 2.14 s\n",
      "    Mean Absolute Error: 8518.465071851242\n",
      "    Mean Squared Error: 3061127831.2831564\n",
      "    R2 Score: -0.22744499257749734\n",
      "1.4. Random Forest Regression:  118.79 s\n",
      "    Mean Absolute Error: 373.8657493285584\n",
      "    Mean Squared Error: 9905412.831957828\n",
      "    R2 Score: 0.9844064617241319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\1_ Universidad\\Trabajo de Grado\\1. Proyecto de Grado\\2. Expertimentación\\AI_OR_Workflow\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\1_ Universidad\\Trabajo de Grado\\1. Proyecto de Grado\\2. Expertimentación\\AI_OR_Workflow\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\1_ Universidad\\Trabajo de Grado\\1. Proyecto de Grado\\2. Expertimentación\\AI_OR_Workflow\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\1_ Universidad\\Trabajo de Grado\\1. Proyecto de Grado\\2. Expertimentación\\AI_OR_Workflow\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\1_ Universidad\\Trabajo de Grado\\1. Proyecto de Grado\\2. Expertimentación\\AI_OR_Workflow\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C8A3E651C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\1_ Universidad\\Trabajo de Grado\\1. Proyecto de Grado\\2. Expertimentación\\AI_OR_Workflow\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Demand Forecast\n",
    "\n",
    "# we are using the data from the population dataset that has the colombian census information for the population of 1123 municipalities since 1985 to 2035, the current year is 2024 and the last census was performed in 2018, the data was taken on december 2023 from the DANE web page.\n",
    "# aditionally we have data of the latitude and longitude of the municipalities.\n",
    "# First we need to check the current forecast, then use 4 ML algorithms and Deep Learning to create a new model. The Machine Learning algorithms are:\n",
    "# - Multiple Linear Regression.\n",
    "# - Regression Tree.\n",
    "# - Support Vector Machine.\n",
    "# - Random Forest Regression.\n",
    "\n",
    "# Then, we need the Mean Absolute Error (MAE) to compare the models. The best model will be used to forecast the demand for the next 30 years.\n",
    "data = population.copy().iloc[:, 20:]\n",
    "data = data.transpose()\n",
    "# train with a random sample of 80% of the data\n",
    "train = data.sample(frac=0.8, random_state=0)\n",
    "test = data.drop(train.index)\n",
    "# 1.1. Multiple Linear Regression\n",
    "start_time = time.time()\n",
    "mean_absolute_errors = []\n",
    "mean_squared_errors = []\n",
    "r2_scores = []\n",
    "# for each column in the data\n",
    "for i in data.columns:\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.array(train.index).reshape(-1, 1), train[i])\n",
    "    predictions = model.predict(np.array(test.index).reshape(-1, 1))\n",
    "    mean_absolute_errors.append(mean_absolute_error(test[i], predictions))\n",
    "    mean_squared_errors.append(mean_squared_error(test[i], predictions))\n",
    "    r2_scores.append(r2_score(test[i], predictions))\n",
    "print(f\"1.1. Multiple Linear Regression: {time.time()-start_time:.2f} s\")\n",
    "print(f'    Mean Absolute Error: {np.mean(mean_absolute_errors)}')\n",
    "print(f'    Mean Squared Error: {np.mean(mean_squared_errors)}')\n",
    "print(f'    R2 Score: {np.mean(r2_scores)}')\n",
    "\n",
    "# 1.2. Regression Tree\n",
    "start_time = time.time()\n",
    "\n",
    "mean_absolute_errors = []\n",
    "mean_squared_errors = []\n",
    "r2_scores = []\n",
    "# for each column in the data\n",
    "for i in data.columns:\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(np.array(train.index).reshape(-1, 1), train[i])\n",
    "    predictions = model.predict(np.array(test.index).reshape(-1, 1))\n",
    "    mean_absolute_errors.append(mean_absolute_error(test[i], predictions))\n",
    "    mean_squared_errors.append(mean_squared_error(test[i], predictions))\n",
    "    r2_scores.append(r2_score(test[i], predictions))\n",
    "print(f\"1.2. Regression Tree: {time.time()-start_time:.2f} s\")\n",
    "print(f'    Mean Absolute Error: {np.mean(mean_absolute_errors)}')\n",
    "print(f'    Mean Squared Error: {np.mean(mean_squared_errors)}')\n",
    "print(f'    R2 Score: {np.mean(r2_scores)}')\n",
    "\n",
    "# 1.3. Support Vector Machine\n",
    "start_time = time.time()\n",
    "\n",
    "mean_absolute_errors = []\n",
    "mean_squared_errors = []\n",
    "r2_scores = []\n",
    "# for each column in the data\n",
    "for i in data.columns:\n",
    "    model = svm.SVR()\n",
    "    model.fit(np.array(train.index).reshape(-1, 1), train[i])\n",
    "    predictions = model.predict(np.array(test.index).reshape(-1, 1))\n",
    "    mean_absolute_errors.append(mean_absolute_error(test[i], predictions))\n",
    "    mean_squared_errors.append(mean_squared_error(test[i], predictions))\n",
    "    r2_scores.append(r2_score(test[i], predictions))\n",
    "print(f\"1.3. Support Vector Machine: {time.time()-start_time:.2f} s\")\n",
    "print(f'    Mean Absolute Error: {np.mean(mean_absolute_errors)}')\n",
    "print(f'    Mean Squared Error: {np.mean(mean_squared_errors)}')\n",
    "print(f'    R2 Score: {np.mean(r2_scores)}')\n",
    "\n",
    "# 1.4. Random Forest Regression\n",
    "start_time = time.time()\n",
    "\n",
    "mean_absolute_errors = []\n",
    "mean_squared_errors = []\n",
    "r2_scores = []\n",
    "# for each column in the data\n",
    "start_time = time.time()\n",
    "\n",
    "for i in data.columns:\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(np.array(train.index).reshape(-1, 1), train[i])\n",
    "    predictions = model.predict(np.array(test.index).reshape(-1, 1))\n",
    "    mean_absolute_errors.append(mean_absolute_error(test[i], predictions))\n",
    "    mean_squared_errors.append(mean_squared_error(test[i], predictions))\n",
    "    r2_scores.append(r2_score(test[i], predictions))\n",
    "print(f\"1.4. Random Forest Regression:  {time.time()-start_time:.2f} s\")\n",
    "print(f'    Mean Absolute Error: {np.mean(mean_absolute_errors)}')\n",
    "print(f'    Mean Squared Error: {np.mean(mean_squared_errors)}')\n",
    "print(f'    R2 Score: {np.mean(r2_scores)}')\n",
    "\n",
    "# 1.5 Deep Learning\n",
    "start_time = time.time()\n",
    "# for the deep learning model we are going to use a simple neural network with 3 layers using the Keras library\n",
    "# we are going to use the same data as before\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "mean_absolute_errors = []\n",
    "mean_squared_errors = []\n",
    "r2_scores = []\n",
    "# for each column in the data\n",
    "for i in data.columns:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=1, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(np.array(train.index, dtype=float), train[i], epochs=150, batch_size=10, verbose=0)\n",
    "    predictions = model.predict(np.array(test.index, dtype=float))\n",
    "    mean_absolute_errors.append(mean_absolute_error(test[i], predictions))\n",
    "    mean_squared_errors.append(mean_squared_error(test[i], predictions))\n",
    "    r2_scores.append(r2_score(test[i], predictions))\n",
    "print(f\"1.5. Deep Learning:  {time.time()-start_time:.2f} s\")\n",
    "print(f'    Mean Absolute Error: {np.mean(mean_absolute_errors)}')\n",
    "print(f'    Mean Squared Error: {np.mean(mean_squared_errors)}')\n",
    "print(f'    R2 Score: {np.mean(r2_scores)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
