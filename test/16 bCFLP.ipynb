{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capacitated Facility Location Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"16 BCFLP\"\n",
    "sample_fraq = 1\n",
    "randomSeed = 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance\n",
    "\n",
    "# Plotting modules\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Linear programming modules\n",
    "import pulp\n",
    "\n",
    "# Machine learning modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# == Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# == Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# == Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "# == Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# == Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      "    food_per_person_per_day: 0.00087617 \n",
      "    transport_cost_per_ton_per_km: 3364.0\n",
      "\n",
      "data information: \n",
      "    population: (1089, 71) \n",
      "    distance: (1089, 1089) \n",
      "    warehouses: \n",
      "    Type  capacity_ton        cost\n",
      "0     1          1074  3111202.75\n",
      "1     2          2418  4804980.75 \n",
      "\n",
      "population memory usage: 0.63 MB\n",
      "distance memory usage: 9.09 MB\n",
      "warehouses memory usage: 0.00 MB\n",
      "Elapsed time: 319.89 s\n"
     ]
    }
   ],
   "source": [
    "# import the data and parameters and check the data\n",
    "\n",
    "data_path = \"data/\"\n",
    "start_time = time.time()\n",
    "# ====Parameters==== #\n",
    "parameters = pd.read_csv(os.path.join(data_path, \"parametros.csv\"))\n",
    "# 1. food_per_person_per_day in tons per day\n",
    "food_per_person_per_day = float(\n",
    "    parameters.loc[parameters[\"parametro\"] == \"comida_por_persona_en_toneladas\"].values[\n",
    "        0\n",
    "    ][1]\n",
    ")\n",
    "# 2. transport_cost_per_ton_per_km in COP per ton per km\n",
    "transport_cost_per_ton_per_km = float(\n",
    "    parameters.loc[\n",
    "        parameters[\"parametro\"] == \"costo_de_transporte_por_tonelada_por_kilomentro\"\n",
    "    ].values[0][1]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"parameters: \\n    food_per_person_per_day: {food_per_person_per_day} \\n    transport_cost_per_ton_per_km: {transport_cost_per_ton_per_km}\\n\"\n",
    ")\n",
    "# ====Parameters==== #\n",
    "\n",
    "# ====importData==== #\n",
    "# 1. population, from data/municipios_procesado.csv\n",
    "population = pd.read_csv(\n",
    "    os.path.join(data_path, \"municipios_procesado.csv\"), index_col=3\n",
    ")\n",
    "# 2. distance, from data/distance_matrix_final.csv\n",
    "distance = pd.read_csv(\n",
    "    os.path.join(data_path, \"distance_matrix_final.csv\"), index_col=0\n",
    ")\n",
    "# 3. warehouses, from data/almacenes.csv\n",
    "warehouses = pd.read_csv(os.path.join(data_path, \"almacenes.csv\"))\n",
    "# ====importData==== #\n",
    "\n",
    "# ====DataProcessing===== #\n",
    "# fill the nan values in population with the minimum '2024' from the departamento of Chocó for the columns 22:\n",
    "population.loc[population.isna().any(axis=1), population.columns[18:]] = (\n",
    "    population[\n",
    "        population[\"2024\"]\n",
    "        == population.loc[population[\"departamento\"] == \"Chocó\"][\"2024\"].min()\n",
    "    ]\n",
    "    .iloc[0, 18:]\n",
    "    .values\n",
    ")\n",
    "# drop the municipalities with nan values in the first column of the distance matrix\n",
    "distance = distance.dropna(subset=[distance.columns[0]], axis=0)\n",
    "distance = distance.dropna(subset=[distance.index[0]], axis=1)\n",
    "# turn the columns of distance into integers\n",
    "distance.columns = distance.columns.astype(int)\n",
    "# Take a sample of the data\n",
    "distance = distance.sample(frac=sample_fraq, random_state=randomSeed)\n",
    "distance = distance.loc[\n",
    "    :, distance.index\n",
    "]  # make the distance matrix symmetric # type: ignore\n",
    "# if there is a 0 value that is not in the diagonal, replace it with the mean of the column\n",
    "for i in distance.index:\n",
    "    for j in distance.columns:\n",
    "        if distance.loc[i, j] == 0 and i != j:\n",
    "            distance.loc[i, j] = np.nan\n",
    "# Drop the nan values\n",
    "distance = distance.dropna()\n",
    "# make the distance matrix symmetric\n",
    "distance = distance.loc[:, distance.index]\n",
    "# turn distance to km\n",
    "distance = distance / 1000\n",
    "# select only the rows in population dpmp that the index is in distance\n",
    "population = population.loc[distance.index]\n",
    "# Check if every value of distance is larger than the linear distance for every pair of municipalities in population lat and lon are in the population dataframe\n",
    "for i in distance.index:\n",
    "    for j in distance.columns:\n",
    "        if i != j:\n",
    "            # get the linear distance\n",
    "            linear_distance = geopy.distance.distance(\n",
    "                (population.loc[i, \"lat\"], population.loc[i, \"lon\"]),\n",
    "                (population.loc[j, \"lat\"], population.loc[j, \"lon\"]),\n",
    "            ).km\n",
    "            # check if the linear distance is larger than the distance in the distance matrix\n",
    "            if linear_distance > distance.loc[i, j]:\n",
    "                distance.loc[i, j] = linear_distance\n",
    "# Check if there are any nan values in distance\n",
    "if distance.isna().any().any():\n",
    "    print(\"There are nan values in the distance matrix\")\n",
    "print(\n",
    "    f\"data information: \\n    population: {population.shape} \\n    distance: {distance.shape} \\n    warehouses: \\n {warehouses} \\n\"\n",
    ")\n",
    "# ====DataProcessing===== #\n",
    "\n",
    "# ====DataInformation==== #\n",
    "# Memory usage of the data\n",
    "print(f\"population memory usage: {population.memory_usage().sum()/1024**2:.2f} MB\")  # type: ignore\n",
    "print(f\"distance memory usage: {distance.memory_usage().sum()/1024**2:.2f} MB\")  # type: ignore\n",
    "print(f\"warehouses memory usage: {warehouses.memory_usage().sum()/1024**2:.2f} MB\")  # type: ignore\n",
    "# ====DataInformation==== #\n",
    "\n",
    "# ====DataChecking==== #\n",
    "# Test to the data if needed\n",
    "# ====DataChecking==== #\n",
    "print(f\"Elapsed time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Demand Forecast\n",
    "\n",
    "we are using the data from the population dataset that has the colombian census information since 1985 to 2035, the current year is 2024 and the last census was performed in 2018, the data was taken on december 2023 from the DANE web page.\n",
    "\n",
    "First we need to check the current forecast, then use 4 ML algorithms and Deep Learning to create a new model. The Machine Learning algorithms are:\n",
    "- Multiple Linear Regression.\n",
    "- Regression Tree.\n",
    "- Support Vector Machine.\n",
    "- Random Forest Regression.\n",
    "\n",
    "Then, we need the Mean Absolute Error (MAE) to compare the models. The best model will be used to forecast the demand for the next 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multiple Linear Regression</th>\n",
       "      <td>2.217933</td>\n",
       "      <td>0.296431</td>\n",
       "      <td>0.205103</td>\n",
       "      <td>0.106126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression Tree</th>\n",
       "      <td>2.203306</td>\n",
       "      <td>0.130626</td>\n",
       "      <td>0.059926</td>\n",
       "      <td>0.352281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>2.127464</td>\n",
       "      <td>0.123849</td>\n",
       "      <td>0.058373</td>\n",
       "      <td>0.638928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regression</th>\n",
       "      <td>12.400050</td>\n",
       "      <td>0.100791</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.620503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network for population regression</th>\n",
       "      <td>28.895403</td>\n",
       "      <td>0.692664</td>\n",
       "      <td>0.725148</td>\n",
       "      <td>-0.522758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               time  mean_absolute_error  \\\n",
       "Multiple Linear Regression                 2.217933             0.296431   \n",
       "Regression Tree                            2.203306             0.130626   \n",
       "Support Vector Machine                     2.127464             0.123849   \n",
       "Random Forest Regression                  12.400050             0.100791   \n",
       "Neural Network for population regression  28.895403             0.692664   \n",
       "\n",
       "                                          mean_squared_error  r2_score  \n",
       "Multiple Linear Regression                          0.205103  0.106126  \n",
       "Regression Tree                                     0.059926  0.352281  \n",
       "Support Vector Machine                              0.058373  0.638928  \n",
       "Random Forest Regression                            0.037755  0.620503  \n",
       "Neural Network for population regression            0.725148 -0.522758  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: SVR()\n"
     ]
    }
   ],
   "source": [
    "# ## 1. Demand Forecast\n",
    "\n",
    "# 1. Demand Forecast\n",
    "\n",
    "data = population.copy().iloc[:, 20:59]\n",
    "data = data.transpose()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=randomSeed)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Multiple Linear Regression\": LinearRegression(),\n",
    "    \"Regression Tree\": DecisionTreeRegressor(\n",
    "        max_depth=100, min_samples_split=2, min_samples_leaf=1, random_state=randomSeed\n",
    "    ),\n",
    "    \"Support Vector Machine\": SVR(C=1.0, kernel=\"rbf\", gamma=\"scale\"),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(\n",
    "        n_estimators=10,\n",
    "        max_depth=5,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=randomSeed,\n",
    "    ),\n",
    "    \"Neural Network for population regression\": MLPRegressor(\n",
    "        hidden_layer_sizes=(10, 10, 10, 10, 10),\n",
    "        activation=\"logistic\",\n",
    "        solver=\"adam\",\n",
    "        alpha=0.01,\n",
    "        batch_size=\"auto\",\n",
    "        learning_rate=\"adaptive\",\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=1000,\n",
    "        shuffle=True,\n",
    "        random_state=randomSeed,\n",
    "    ),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float(\"-inf\")\n",
    "results = {}\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    mean_absolute_errors = []\n",
    "    mean_squared_errors = []\n",
    "    r2_scores = []\n",
    "\n",
    "    # For each column in the data\n",
    "    for column in data.columns:\n",
    "        model.fit(train.index.values.reshape(-1, 1), train[column])\n",
    "        predictions = model.predict(test.index.values.reshape(-1, 1))\n",
    "        mean_absolute_errors.append(mean_absolute_error(test[column], predictions))\n",
    "        mean_squared_errors.append(mean_squared_error(test[column], predictions))\n",
    "        r2_scores.append(r2_score(test[column], predictions))\n",
    "\n",
    "    avg_r2_score = np.mean(r2_scores)\n",
    "    results[model_name] = {\n",
    "        \"time\": time.time() - start_time,\n",
    "        \"mean_absolute_error\": np.mean(mean_absolute_errors),\n",
    "        \"mean_squared_error\": np.mean(mean_squared_errors),\n",
    "        \"r2_score\": avg_r2_score,\n",
    "    }\n",
    "\n",
    "    if avg_r2_score > best_score:\n",
    "        best_score = avg_r2_score\n",
    "        best_model = model\n",
    "\n",
    "# results to dataframe\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "display(results_df)\n",
    "\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "\n",
    "# Create the forecast per municipality since 1985 to 2024+30 years\n",
    "# Create a list to store all columns\n",
    "columns = []\n",
    "forecast = pd.DataFrame(index=np.arange(1985, 2024 + 30))\n",
    "# Iterate over each column in data\n",
    "for column in data.columns:\n",
    "    best_model.fit(data.index.values.reshape(-1, 1), data[column])  # type: ignore\n",
    "    column_data = pd.DataFrame(\n",
    "        best_model.predict(np.arange(1985, 2024 + 30).reshape(-1, 1)), columns=[column]  # type: ignore\n",
    "    )\n",
    "    columns.append(column_data)\n",
    "\n",
    "# Concatenate all columns at once\n",
    "forecast = pd.concat(columns, axis=1)\n",
    "\n",
    "\n",
    "# Inverse the standardization\n",
    "data = pd.DataFrame(\n",
    "    scaler.inverse_transform(data), index=data.index, columns=data.columns  # type: ignore\n",
    ")  # type: ignore\n",
    "forecast = pd.DataFrame(\n",
    "    scaler.inverse_transform(forecast), index=forecast.index, columns=forecast.columns  # type: ignore\n",
    ")  # type: ignore\n",
    "forecast.index = pd.RangeIndex(start=1985, stop=2024 + 30, step=1)\n",
    "\n",
    "# Plot the forecast\n",
    "fig = go.Figure()\n",
    "for column in forecast.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast.index,\n",
    "            y=forecast[column],\n",
    "            mode=\"lines+markers\",\n",
    "            name=column,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Population Forecast\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"Population\",\n",
    "    legend_title=\"Municipality\",\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(f\"html/1 {test_name} forecast.html\")\n",
    "\n",
    "# Select the year 2024+10 and add the population to the population dataframe\n",
    "population[\"forecast\"] = forecast.loc[2024 + 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set facility types\n",
    "\n",
    "We have 3 types of facilities:\n",
    "- Type 1: Small facility.\n",
    "- Type 2: Medium facility.\n",
    "- Type 3: Large facility.\n",
    "\n",
    "for each facility type we have the following information:\n",
    "- Fixed cost.\n",
    "- Variable cost.\n",
    "\n",
    "The proposal is to use a mathematical model to determine the number of facilities of each type to minimize the total cost, in order to satisfy the demand. and be able to train a classifier to predict the type of facility that will be needed for the hole country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Objective function: 3773603667.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Clasifications:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([(1.0, 0.0), (0.0, 1.0), (3.0, 0.0), (0.0, 2.0), (0.0, 3.0),\n",
       "       (0.0, 5.0), (0.0, 4.0), (0.0, 8.0), (0.0, 9.0), (0.0, 26.0)],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization of the model\n",
    "p = population.copy()[\"forecast\"]\n",
    "\n",
    "# ====Parameters==== #\n",
    "c_j = warehouses[\"capacity_ton\"].values.astype(float)\n",
    "f_j = warehouses[\"cost\"].values.astype(float)\n",
    "\n",
    "\n",
    "p_i = p.values.astype(int)\n",
    "n = food_per_person_per_day * 7\n",
    "d_i = p_i * n\n",
    "# Lambda = 2 for the top 32 municipalities, 1 for the rest\n",
    "lambda_i = np.ones(len(p_i)) * 1.1\n",
    "lambda_i[np.argsort(p_i)[-32:]] = 1.5\n",
    "# ====Parameters==== #\n",
    "\n",
    "\n",
    "# Decision variables: $x_{ij}$\n",
    "I = range(len(p_i))\n",
    "J = range(len(c_j))\n",
    "model = pulp.LpProblem(\"UFLP\", pulp.LpMinimize)\n",
    "x = pulp.LpVariable.dicts(\n",
    "    \"x\", ((i, j) for i in I for j in J), lowBound=0, cat=\"Integer\"\n",
    ")\n",
    "y = pulp.LpVariable.dicts(\"y\", ((i, j) for i in I for j in J), cat=\"Binary\")\n",
    "# Objective function\n",
    "model += (\n",
    "    pulp.lpSum(f_j[j] * x[(i, j)] for i in I for j in J),\n",
    "    \"Total cost of the facilities\",\n",
    ")\n",
    "# Constraints\n",
    "for i in I:\n",
    "    model += (\n",
    "        pulp.lpSum(c_j[j] * x[(i, j)] for j in J) >= d_i[i] * lambda_i[i],\n",
    "        f\"Population demand {i}\",\n",
    "    )\n",
    "    model += (\n",
    "        pulp.lpSum(x[(i, j)] for j in J) >= 1,\n",
    "        f\"Facility assignment {i}\",\n",
    "    )\n",
    "    model += (\n",
    "        pulp.lpSum(y[(i, j)] for j in J) == 1,\n",
    "        f\"Faacility assignment __ {i}\",\n",
    "    )\n",
    "    for j in J:\n",
    "        model += (\n",
    "            x[(i, j)] <= 100 * y[(i, j)],\n",
    "            f\"Fsacility assignment _ {i} _ {j}\",\n",
    "        )\n",
    "\n",
    "model += pulp.lpSum(x[(i, j)] * c_j[j] for i in I for j in J) >= pulp.lpSum(\n",
    "    d_i[i] * lambda_i[i] for i in I\n",
    ")\n",
    "\n",
    "\n",
    "# Solve the model\n",
    "model.solve(\n",
    "    solver=pulp.PULP_CBC_CMD(\n",
    "        logPath=f\"logs/2 {test_name}.log\",\n",
    "        msg=False,\n",
    "        timeLimit=5 * 60,\n",
    "        threads=os.cpu_count(),\n",
    "    )\n",
    ")\n",
    "# Results\n",
    "print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
    "print(f\"Objective function: {pulp.value(model.objective)}\")\n",
    "df = pd.DataFrame(\n",
    "    [[pulp.value(x[(i, j)]) for j in J] for i in I],\n",
    "    columns=[f\"Facility {j}\" for j in J],\n",
    "    index=p.index,\n",
    ")\n",
    "df[\"demand\"] = d_i\n",
    "df[\"satisfied\"] = sum(df[f\"Facility {j}\"] * c_j[j] for j in J)\n",
    "df[\"cost\"] = sum(df[f\"Facility {j}\"] * f_j[j] for j in J)\n",
    "df[\"comb\"] = df.apply(lambda x: tuple(x[: len(J)]), axis=1)\n",
    "\n",
    "display(\"Clasifications:\", df.comb.unique().size, df.comb.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set facility capacity\n",
    "\n",
    "We have m types of facilities with different capacities, the proposal is to use the data generated in the previous step to determine the capacity of each facility type in order to satisfy the demand.\n",
    "Machine Learning algorithms will be used to Classify the type of facility that will be needed for each municipality.\n",
    "- Decision Tree.\n",
    "- Linear Discriminant Analysis.\n",
    "- Logistic Regression.\n",
    "- Support Vector Machine.\n",
    "\n",
    "and deep learning to create a new model. The best model will be used to determine the capacity of each facility type.\n",
    "\n",
    "The objective is to predict 'satisfied' with the demand of each municipality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1342/3952257875.py:10: DeprecationWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand</th>\n",
       "      <th>satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.922341</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167.092628</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1321.561382</td>\n",
       "      <td>2418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1279.444766</td>\n",
       "      <td>2418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1834.093670</td>\n",
       "      <td>3222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1775.552372</td>\n",
       "      <td>3222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3185.713816</td>\n",
       "      <td>4836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2734.838487</td>\n",
       "      <td>4836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3331.137884</td>\n",
       "      <td>7254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4250.392668</td>\n",
       "      <td>7254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5450.069165</td>\n",
       "      <td>9672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7290.713082</td>\n",
       "      <td>12090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12809.547573</td>\n",
       "      <td>19344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13582.746570</td>\n",
       "      <td>21762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41811.759388</td>\n",
       "      <td>62868.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          demand  satisfied\n",
       "0      13.922341     1074.0\n",
       "1     167.092628     1074.0\n",
       "2    1321.561382     2418.0\n",
       "3    1279.444766     2418.0\n",
       "4    1834.093670     3222.0\n",
       "5    1775.552372     3222.0\n",
       "6    3185.713816     4836.0\n",
       "7    2734.838487     4836.0\n",
       "8    3331.137884     7254.0\n",
       "9    4250.392668     7254.0\n",
       "10   5450.069165     9672.0\n",
       "11   7290.713082    12090.0\n",
       "12  12809.547573    19344.0\n",
       "13  13582.746570    21762.0\n",
       "14  41811.759388    62868.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.01 s\n",
      "    Accuracy: 1.0\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Linear Discriminant Analysis: 0.01 s\n",
      "    Accuracy: 0.9333333333333333\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.97      0.95      0.95        15\n",
      "weighted avg       0.96      0.93      0.93        15\n",
      "\n",
      "Logistic Regression: 0.01 s\n",
      "    Accuracy: 0.2\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      1.00      0.31         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.20        15\n",
      "   macro avg       0.12      0.20      0.13        15\n",
      "weighted avg       0.09      0.20      0.11        15\n",
      "\n",
      "Support Vector Machine: 0.01 s\n",
      "    Accuracy: 0.8\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       0.33      0.50      0.40         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.70      0.75      0.72        15\n",
      "weighted avg       0.73      0.80      0.76        15\n",
      "\n",
      "Deep Neural Network: 0.58 s\n",
      "    Accuracy: 1.0\n",
      "    Confusion Matrix: [[2 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "    Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "\n",
      "Best model: DecisionTreeClassifier(max_depth=100)\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(df.copy(), population.copy(), left_index=True, right_index=True)\n",
    "population[\"demand\"] = d_i\n",
    "population[\"_satisfied\"] = df[\"satisfied\"]\n",
    "population[\"_cost\"] = df[\"cost\"]\n",
    "\n",
    "\n",
    "data = data[[\"demand\", \"lat\", \"lon\", \"satisfied\", \"cost\"]]\n",
    "\n",
    "# Create table with the unique cases of satisfied and cost values, with a random sample of n of the demand, lat and lon\n",
    "unique_cases = data.groupby([\"satisfied\", \"cost\"]).apply(\n",
    "    lambda x: x.sample(n=2, random_state=randomSeed) if len(x) > 2 else x\n",
    ")\n",
    "data = unique_cases.reset_index(drop=True)[[\"demand\", \"satisfied\"]]\n",
    "display(data)\n",
    "le = LabelEncoder()\n",
    "data[\"satisfied\"] = le.fit_transform(data[\"satisfied\"])\n",
    "scaler = MinMaxScaler()\n",
    "data[[\"demand\"]] = scaler.fit_transform(data[[\"demand\"]])\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data.drop(columns=[\"satisfied\"]), data[\"satisfied\"], test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "train_x, test_x = data.drop(columns=[\"satisfied\"]), data.drop(columns=[\"satisfied\"])\n",
    "train_y, test_y = data[\"satisfied\"], data[\"satisfied\"]\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "        max_depth=100, min_samples_split=2, min_samples_leaf=1\n",
    "    ),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine\": SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\"),\n",
    "    \"Deep Neural Network\": MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100, 100),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=1000,\n",
    "        random_state=0,\n",
    "    ),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float(\"-inf\")\n",
    "results = {}\n",
    "metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"confusion_matrix\": [],\n",
    "    \"classification_report\": [],\n",
    "    \"time\": [],\n",
    "}\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(train_x, train_y)\n",
    "    predictions = model.predict(test_x)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    confusion = confusion_matrix(test_y, predictions)\n",
    "    classification = classification_report(test_y, predictions, zero_division=0)\n",
    "    results[model_name] = {\n",
    "        \"time\": time.time() - start_time,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": confusion,\n",
    "        \"classification_report\": classification,\n",
    "    }\n",
    "\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_model = model\n",
    "\n",
    "    metrics[\"accuracy\"].append(accuracy)\n",
    "    metrics[\"confusion_matrix\"].append(confusion)\n",
    "    metrics[\"classification_report\"].append(classification)\n",
    "    metrics[\"time\"].append(time.time() - start_time)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: {metrics['time']:.2f} s\")\n",
    "    print(f\"    Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"    Confusion Matrix: {metrics['confusion_matrix']}\")\n",
    "    print(f\"    Classification Report: {metrics['classification_report']}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "\n",
    "# Classify the data for the population data for every model\n",
    "for model_name, model in models.items():\n",
    "    population[f\"_satisfied {model_name}\"] = model.predict(population[[\"demand\"]])\n",
    "    population[f\"_satisfied {model_name}\"] = le.inverse_transform(\n",
    "        population[f\"_satisfied {model_name}\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solve the CFLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (1089, 5)\n",
      "----- 16 BCFLP ----- || size (1089, 1089) || Current time: 1716901271.8145957\n",
      "Total demand: 275442.54421039956\n",
      "Total capacity: 1369482.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal demand: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(h_i)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal capacity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(v_j)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 67\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpulp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPULP_CBC_CMD\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogPath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogs/5 \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.log\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeLimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m## Results\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpulp\u001b[38;5;241m.\u001b[39mLpStatus[model\u001b[38;5;241m.\u001b[39mstatus]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tesis/AI_OR_Workflow/.venv/lib/python3.10/site-packages/pulp/pulp.py:1883\u001b[0m, in \u001b[0;36mLpProblem.solve\u001b[0;34m(self, solver, **kwargs)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[38;5;66;03m# time it\u001b[39;00m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartClock()\n\u001b[0;32m-> 1883\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactualSolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopClock()\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestoreObjective(wasNone, dummyVar)\n",
      "File \u001b[0;32m~/tesis/AI_OR_Workflow/.venv/lib/python3.10/site-packages/pulp/apis/coin_api.py:112\u001b[0m, in \u001b[0;36mCOIN_CMD.actualSolve\u001b[0;34m(self, lp, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactualSolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, lp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Solve a well formulated lp problem\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_CBC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tesis/AI_OR_Workflow/.venv/lib/python3.10/site-packages/pulp/apis/coin_api.py:178\u001b[0m, in \u001b[0;36mCOIN_CMD.solve_CBC\u001b[0;34m(self, lp, use_mps)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     cbc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(args, stdout\u001b[38;5;241m=\u001b[39mpipe, stderr\u001b[38;5;241m=\u001b[39mpipe, stdin\u001b[38;5;241m=\u001b[39mdevnull)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pipe:\n\u001b[1;32m    180\u001b[0m         pipe\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = population.copy()[\n",
    "    [\n",
    "        \"demand\",\n",
    "        \"_satisfied\",\n",
    "        \"_cost\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "    ]\n",
    "]\n",
    "dist = distance.copy()\n",
    "\n",
    "print(f\"size: {data.shape}\")\n",
    "\n",
    "h_i = data[\"demand\"].values  # demand of customer i\n",
    "c_ij = (\n",
    "    dist.loc[data.index, data.index] * transport_cost_per_ton_per_km  # type: ignore\n",
    ").values  # distance between customer i and j\n",
    "f_j = data[\"_cost\"].values  # fixed cost to open a facility at site j\n",
    "v_j = data[\n",
    "    \"_satisfied\"\n",
    "].values  # maximum capacity of facility j or the amount of capacity that it can be satisfied\n",
    "\n",
    "# Inside the loop, for testing we will work with the last group\n",
    "## Create the variables\n",
    "I = range(len(h_i))\n",
    "J = range(len(f_j))\n",
    "x_j = pulp.LpVariable.dicts(\"x\", J, cat=\"Binary\")\n",
    "y_ij = pulp.LpVariable.dicts(\n",
    "    \"y\", ((i, j) for i in I for j in J), lowBound=0, upBound=1, cat=\"Continuous\"\n",
    ")\n",
    "## Create the model\n",
    "model = pulp.LpProblem(\"CFLP\", pulp.LpMinimize)\n",
    "## Objective function\n",
    "model += (\n",
    "    pulp.lpSum(f_j[j] * x_j[j] for j in J)\n",
    "    + pulp.lpSum(c_ij[i][j] * y_ij[(i, j)] for i in I for j in J),\n",
    "    \"Total cost\",\n",
    ")\n",
    "## Constraints\n",
    "for i in I:\n",
    "    model += pulp.lpSum(y_ij[(i, j)] for j in J) == 1, f\"Population demand {i}\"\n",
    "for j in J:\n",
    "    for i in I:\n",
    "        model += y_ij[(i, j)] <= x_j[j], f\"Facility assignment {i} {j}\"\n",
    "for j in J:\n",
    "    model += (\n",
    "        pulp.lpSum(h_i[i] * y_ij[(i, j)] for i in I) <= v_j[j],\n",
    "        f\"Facility capacity {j}\",\n",
    "    )\n",
    "# Save the parameters to an excel file where each sheet is parameter h, c, f, v\n",
    "df_h = pd.DataFrame(h_i, columns=[\"demand\"], index=data.index)\n",
    "df_c = pd.DataFrame(c_ij, columns=data.index, index=data.index)\n",
    "df_f = pd.DataFrame(f_j, columns=[\"cost\"], index=data.index)\n",
    "df_v = pd.DataFrame(v_j, columns=[\"capacity\"], index=data.index)\n",
    "\n",
    "with pd.ExcelWriter(f\"parameters/{test_name}.xlsx\") as writer:\n",
    "    df_h.to_excel(writer, sheet_name=\"demand\")\n",
    "    df_c.to_excel(writer, sheet_name=\"distance\")\n",
    "    df_f.to_excel(writer, sheet_name=\"cost\")\n",
    "    df_v.to_excel(writer, sheet_name=\"capacity\")\n",
    "del df_h, df_c, df_f, df_v\n",
    "\n",
    "## Solve the model\n",
    "print(f\"----- {test_name} ----- || size {c_ij.shape} || Current time: {time.time()}\")\n",
    "print(f\"Total demand: {sum(h_i)}\\nTotal capacity: {sum(v_j)}\")\n",
    "start_time = time.time()\n",
    "model.solve(\n",
    "    solver=pulp.PULP_CBC_CMD(\n",
    "        logPath=f\"logs/5 {test_name}.log\",\n",
    "        msg=False,\n",
    "        timeLimit=7 * 60 * 60,\n",
    "        threads=os.cpu_count(),\n",
    "    )\n",
    ")\n",
    "## Results\n",
    "print(f\"Status: {pulp.LpStatus[model.status]}\")\n",
    "print(f\"Objective function: {pulp.value(model.objective)}\")\n",
    "print(f\"Number of facilities: {pulp.value(pulp.lpSum(x_j[j] for j in J))}\")\n",
    "print(f\"Solution time: {time.time() - start_time :.2f} s\")\n",
    "## Save the solution\n",
    "df_y = pd.DataFrame(\n",
    "    [[pulp.value(y_ij[(i, j)]) for j in J] for i in I],\n",
    "    data.index,\n",
    "    data.index,\n",
    ")\n",
    "df_x = pd.DataFrame([pulp.value(x_j[j]) for j in J], columns=[\"open\"], index=data.index)\n",
    "with pd.ExcelWriter(\n",
    "    f\"solutions/{test_name} {pulp.value(model.objective)}.xlsx\"\n",
    ") as writer:\n",
    "    df_y.to_excel(writer, sheet_name=\"Y\")\n",
    "    df_x.to_excel(writer, sheet_name=\"X\")\n",
    "\n",
    "\n",
    "del x_j, y_ij, I, J, h_i, c_ij, f_j, v_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. plot the results of the CFLP in a map with the contours of Colombia\n",
    "fig = go.Figure()\n",
    "## Add the municipalities and the color with the cluster to which they belong\n",
    "# Add the arrows that show the amount of the demand that each facility satisfies\n",
    "for i in data.index:\n",
    "    for j in data.index:\n",
    "        if df_y.loc[i, j] > 0:\n",
    "            fig.add_trace(\n",
    "                go.Scattermapbox(\n",
    "                    lat=[data.loc[i, \"lat\"], data.loc[j, \"lat\"]],\n",
    "                    lon=[data.loc[i, \"lon\"], data.loc[j, \"lon\"]],\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(width=df_y.loc[i, j] * 5, color=\"orange\"),\n",
    "                    opacity=df_y.loc[i, j],\n",
    "                )\n",
    "            )\n",
    "# Add the Open facilitys\n",
    "for j in data.index:\n",
    "    if int(df_x.loc[j, \"open\"]) > 0:  # type: ignore\n",
    "        fig.add_trace(\n",
    "            go.Scattermapbox(\n",
    "                lat=[data.loc[j, \"lat\"]],\n",
    "                lon=[data.loc[j, \"lon\"]],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=10, color=\"red\"),\n",
    "                text=f\"{j}\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"CFLP {pulp.value(model.objective)}\",\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        center=dict(lon=-74, lat=4),\n",
    "        zoom=4,\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    ")\n",
    "# fig.show()\n",
    "# Save the html\n",
    "fig.write_html(f\"solutions/6 {test_name}.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 15))\n",
    "m = Basemap(\n",
    "    projection=\"merc\",\n",
    "    llcrnrlat=-5,\n",
    "    urcrnrlat=13,\n",
    "    llcrnrlon=-82,\n",
    "    urcrnrlon=-66,\n",
    "    lat_ts=0,\n",
    "    resolution=\"i\",\n",
    "    ax=ax,\n",
    ")\n",
    "m.drawcountries()\n",
    "m.drawmapboundary(fill_color=\"aqua\")\n",
    "m.fillcontinents(color=\"lightgreen\", lake_color=\"aqua\")\n",
    "m.drawcoastlines()\n",
    "m.drawparallels(range(-10, 20, 5), labels=[1, 0, 0, 0])\n",
    "m.drawmeridians(range(-90, -60, 5), labels=[0, 0, 0, 1])\n",
    "\n",
    "# Plot municipalities\n",
    "x, y = m(data[\"lon\"].values, data[\"lat\"].values)\n",
    "m.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    s=(data[\"demand\"] / max(data[\"demand\"])) * 100,\n",
    "    color=\"grey\",\n",
    "    edgecolor=\"k\",\n",
    "    zorder=5,\n",
    ")\n",
    "\n",
    "# Plot demand satisfaction arrows\n",
    "for i in data.index:\n",
    "    for j in data.index:\n",
    "        if df_y.loc[i, j] > 0:\n",
    "            start_lat = data.loc[i, \"lat\"]\n",
    "            start_lon = data.loc[i, \"lon\"]\n",
    "            end_lat = data.loc[j, \"lat\"]\n",
    "            end_lon = data.loc[j, \"lon\"]\n",
    "            x_start, y_start = m(start_lon, start_lat)\n",
    "            x_end, y_end = m(end_lon, end_lat)\n",
    "            m.plot(\n",
    "                [x_start, x_end],\n",
    "                [y_start, y_end],\n",
    "                color=\"orange\",\n",
    "                linewidth=df_y.loc[i, j] * 5,\n",
    "                alpha=0.6,\n",
    "                zorder=4,\n",
    "            )\n",
    "\n",
    "# Plot open facilities\n",
    "for j in data.index:\n",
    "    if int(df_x.loc[j, \"open\"]) > 0:\n",
    "        x, y = m(data.loc[j, \"lon\"], data.loc[j, \"lat\"])\n",
    "        m.scatter(x, y, color=\"red\", s=100, marker=\"*\", zorder=6)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"CFLP Total Cost: {pulp.value(model.objective):,.2f}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
